{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1290f794-9477-4e45-ab20-81d04c040fc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## langcain agent demo for ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edb2e3-ded0-497c-bbaa-d8170e6c653d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### bedrock已经GA，不需要再手动安装\n",
    "%pip install ../bedrock-workshop-main/dependencies/boto3-1.26.140-py3-none-any.whl\n",
    "%pip install ../bedrock-workshop-main/dependencies/botocore-1.29.140-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f25b23f-cb6f-427e-901d-3d4e1fab21b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip config unset global.index-url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf80354-7edd-4403-9c8b-97a4712f4dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain[all]\n",
    "!pip install langchain-experimental\n",
    "#!pip install sagemaker --upgrade\n",
    "!pip install  --upgrade boto3\n",
    "!pip install requests_aws4auth\n",
    "!pip install opensearch-py\n",
    "!pip install pydantic==1.10.0\n",
    "#!pip install PyAthena[SQLAlchemy]==1.0.0\n",
    "#!pip install PyAthena[JDBC]==1.0.0\n",
    "#!pip install openai\n",
    "!pip install sqlalchemy-redshift\n",
    "!pip install redshift_connector\n",
    "!pip install SQLAlchemy\n",
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b216f11-a2b5-4f0b-b4de-060a1a64076a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## initial sagemaker env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19f05414-d44b-464e-a0c7-46c317378ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
      "sagemaker bucket: sagemaker-us-west-2-687912291502\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "from typing import Dict\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3aed78-e14b-4d30-93d3-2871d6603bd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## intial lanchain lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aae9f94-a8df-49b5-b22b-f89e8d756b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferWindowMemory,ConversationBufferMemory\n",
    "from langchain import LLMChain\n",
    "from typing import Any, Dict, List, Union,Mapping, Optional, TypeVar, Union\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"]= \"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\"\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "aos_endpoint=\"vpc-llm-rag-aos-seg3mzhpp76ncpxezdqtcsoiga.us-west-2.es.amazonaws.com\"\n",
    "embedding_endpoint_name=\"bge-zh-15-2023-09-25-07-02-01-080-endpoint\"\n",
    "region='us-west-2'\n",
    "username=\"admin\"\n",
    "passwd=\"(OL>0p;/\"\n",
    "index_name=\"metadata-index\"\n",
    "size=10\n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "region = boto3.Session().region_name\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, 'es', session_token=credentials.token)\n",
    "pwdauth = (username, passwd)\n",
    "\n",
    "### for sqlcoder\n",
    "class TextGenContentHandler2(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": model_kwargs\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        #print(response_json)\n",
    "        #sql_result=response_json[\"outputs\"].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip().replace(\"\\\\n\",\" \") + \";\"\n",
    "        sql_result=response_json[\"outputs\"]\n",
    "        return sql_result\n",
    "\n",
    "\n",
    "content_hander2=TextGenContentHandler2()\n",
    "\n",
    "## for embedding\n",
    "class EmbeddingContentHandler(EmbeddingsContentHandler):\n",
    "    parameters = {\n",
    "        \"max_new_tokens\": 50,\n",
    "        \"temperature\": 0,\n",
    "        \"min_length\": 10,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "    }\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode('utf-8')\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"sentence_embeddings\"]\n",
    "\n",
    "embedding_content_handler=EmbeddingContentHandler()\n",
    "    \n",
    "sm_embeddings = SagemakerEndpointEmbeddings(\n",
    "    # endpoint_name=\"endpoint-name\", \n",
    "    # credentials_profile_name=\"credentials-profile-name\", \n",
    "    #endpoint_name=\"huggingface-textembedding-bloom-7b1-fp1-2023-04-17-03-31-12-148\", \n",
    "    endpoint_name=\"bge-zh-15-2023-09-25-07-02-01-080-endpoint\",\n",
    "    region_name=\"us-west-2\", \n",
    "    content_handler=embedding_content_handler\n",
    ")\n",
    "\n",
    "\n",
    "parameters = {\n",
    "  \"max_new_tokens\": 350,\n",
    "  #\"do_sample\":False,\n",
    "  #\"temperatual\" : 0\n",
    "  #\"no_repeat_ngram_size\": 2,\n",
    "}\n",
    "sm_sql_llm=SagemakerEndpoint(\n",
    "        endpoint_name=\"sqlcoder-2023-10-07-01-50-46-950-endpoint\",\n",
    "        region_name=\"us-west-2\", \n",
    "        model_kwargs=parameters,\n",
    "        content_handler=content_hander2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9330b-0204-4e5a-bc7b-36ec7fd20818",
   "metadata": {
    "tags": []
   },
   "source": [
    "## func for agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0819cc2-5be1-4f78-8826-90c3ff2c72d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import os\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain import LLMChain\n",
    "\n",
    "\n",
    "\n",
    "def aos_knn_search(client, field,q_embedding, index, size=1):\n",
    "    if not isinstance(client, OpenSearch):   \n",
    "        client = OpenSearch(\n",
    "            hosts=[{'host': aos_endpoint, 'port': 443}],\n",
    "            http_auth = pwdauth,\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            connection_class=RequestsHttpConnection\n",
    "        )\n",
    "    query = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                field: {\n",
    "                    \"vector\": q_embedding,\n",
    "                    \"k\": size\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    opensearch_knn_respose = []\n",
    "    query_response = client.search(\n",
    "        body=query,\n",
    "        index=index\n",
    "    )\n",
    "    opensearch_knn_respose = [{'idx':item['_source'].get('idx',1),'database_name':item['_source']['database_name'],'table_name':item['_source']['table_name'],'query_desc_text':item['_source']['query_desc_text'],\"score\":item[\"_score\"]}  for item in query_response[\"hits\"][\"hits\"]]\n",
    "    return opensearch_knn_respose\n",
    "\n",
    "def aos_reverse_search(client, index_name, field, query_term, exactly_match=False, size=1):\n",
    "    \"\"\"\n",
    "    search opensearch with query.\n",
    "    :param host: AOS endpoint\n",
    "    :param index_name: Target Index Name\n",
    "    :param field: search field\n",
    "    :param query_term: query term\n",
    "    :return: aos response json\n",
    "    \"\"\"\n",
    "    if not isinstance(client, OpenSearch):   \n",
    "        client = OpenSearch(\n",
    "            hosts=[{'host': aos_endpoint, 'port': 443}],\n",
    "            http_auth = pwdauth,\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            connection_class=RequestsHttpConnection\n",
    "        )\n",
    "    query = None\n",
    "    if exactly_match:\n",
    "        query =  {\n",
    "            \"query\" : {\n",
    "                \"match_phrase\":{\n",
    "                    \"doc\": {\n",
    "                        \"query\": query_term,\n",
    "                        \"analyzer\": \"ik_smart\"\n",
    "                      }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        query = {\n",
    "            \"size\": size,\n",
    "            \"query\": {\n",
    "                \"query_string\": {\n",
    "                \"default_field\": \"query_desc_text\",  \n",
    "                \"query\": query_term         \n",
    "              }\n",
    "            },\n",
    "           \"sort\": [{\n",
    "               \"_score\": {\n",
    "                   \"order\": \"desc\"\n",
    "               }\n",
    "           }]\n",
    "    }        \n",
    "    query_response = client.search(\n",
    "        body=query,\n",
    "        index=index_name\n",
    "    )\n",
    "    result_arr = [{'idx':item['_source'].get('idx',1),'database_name':item['_source']['database_name'],'table_name':item['_source']['table_name'],'query_desc_text':item['_source']['query_desc_text'],\"score\":item[\"_score\"]}  for item in query_response[\"hits\"][\"hits\"]]\n",
    "    return result_arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_vector_by_sm_endpoint(questions, sm_client, endpoint_name):\n",
    "    parameters = {\n",
    "    }\n",
    "\n",
    "    response_model = sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": questions,\n",
    "                \"parameters\": parameters,\n",
    "                \"is_query\" : True,\n",
    "                \"instruction\" :  \"为这个句子生成表示以用于检索相关文章：\"\n",
    "            }\n",
    "        ),\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "    json_str = response_model['Body'].read().decode('utf8')\n",
    "    json_obj = json.loads(json_str)\n",
    "    embeddings = json_obj['sentence_embeddings']\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_topk_items(opensearch_query_response, topk=5):\n",
    "    opensearch_knn_nodup = []\n",
    "    unique_ids = set()\n",
    "    for item in opensearch_query_response:\n",
    "        if item['id'] not in unique_ids:\n",
    "            opensearch_knn_nodup.append(item['score'], item['idx'],item['database_name'],item['table_name'],item['query_desc_text'])\n",
    "            unique_ids.add(item['id'])\n",
    "    return opensearch_knn_nodup\n",
    "\n",
    "\n",
    "\n",
    "def k_nn_ingestion_by_aos(docs,index,hostname,username,passwd):\n",
    "    auth = (username, passwd)\n",
    "    search = OpenSearch(\n",
    "        hosts = [{'host': aos_endpoint, 'port': 443}],\n",
    "        ##http_auth = awsauth ,\n",
    "        http_auth = auth ,\n",
    "        use_ssl = True,\n",
    "        verify_certs = True,\n",
    "        connection_class = RequestsHttpConnection\n",
    "    )\n",
    "    for doc in docs:\n",
    "        query_desc_embedding = doc['query_desc_embedding']\n",
    "        database_name = doc['database_name']\n",
    "        table_name = doc['table_name']\n",
    "        query_desc_text = doc[\"query_desc_text\"]\n",
    "        document = { \"query_desc_embedding\": query_desc_embedding, 'database_name':database_name, \"table_name\": table_name,\"query_desc_text\":query_desc_text}\n",
    "        search.index(index=index, body=document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb5728d-e84a-487f-a643-4297954f7631",
   "metadata": {},
   "source": [
    "* for local test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5da7a2d7-f9db-4420-ac31-c9873f59fcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'idx': 1, 'database_name': 'llm', 'table_name': 'ads_bi_quality_monitor_shipping_detail', 'query_desc_text': '最近一个月温度合格的派车单数量', 'score': 0.94651985}]\n",
      "[{'idx': 1, 'database_name': 'llm', 'table_name': 'ads_bi_quality_monitor_shipping_detail', 'query_desc_text': '最近一个月温度合格的派车单数量', 'score': 2.0931337}]\n"
     ]
    }
   ],
   "source": [
    "query=\"上个月温度合格的派车单数量\"\n",
    "query_embedding = get_vector_by_sm_endpoint(query, sm_client, embedding_endpoint_name)\n",
    "\n",
    "client=None\n",
    "rets=aos_knn_search(client, \"query_desc_embedding\",query_embedding[0], index_name, size=1)\n",
    "print(rets)\n",
    "\n",
    "rets=opensearch_query_response = aos_reverse_search(client, index_name, \"query_desc_text\", query)   \n",
    "print(rets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa302e0a-b8ed-4fa0-934e-ab4ff0740316",
   "metadata": {
    "tags": []
   },
   "source": [
    "## major chain pipeline ################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca53df-0f55-46ec-85a9-36316e25008b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 0: index 创建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ccff8-4361-4f77-a42f-9d2c64ebe387",
   "metadata": {},
   "source": [
    "PUT metadata-index\n",
    "{\n",
    "    \"settings\" : {\n",
    "        \"index\":{\n",
    "            \"number_of_shards\" : 5,\n",
    "            \"number_of_replicas\" : 0,\n",
    "            \"knn\": \"true\",\n",
    "            \"knn.algo_param.ef_search\": 32\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"metadata_type\" : {\n",
    "                \"type\" : \"keyword\"\n",
    "            },\n",
    "            \"database_name\": {\n",
    "                \"type\" : \"keyword\"\n",
    "            },\n",
    "            \"table_name\": {\n",
    "               \"type\" : \"keyword\"\n",
    "            },\n",
    "            \"query_desc_text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"ik_max_word\",\n",
    "                \"search_analyzer\": \"ik_smart\"\n",
    "            },\n",
    "            \"query_desc_embedding\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 768,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"engine\": \"faiss\",\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 512,\n",
    "                        \"m\": 32\n",
    "                    }\n",
    "                }            \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ef73a-d691-4d30-b35e-1a5254cdb8d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1: data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9c564-9d44-4ba3-a279-34b6df2aa3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_querys = \"\"\"temperature delivery order data\"\"\"\n",
    "querys = all_querys.split(\"\\n\")\n",
    "\n",
    "all_tables = \"\"\"ads_bi_quality_monitor_shipping_detail\"\"\"\n",
    "tables=all_tables.split(\"\\n\")\n",
    "\n",
    "all_dbs = \"\"\"llm\"\"\"\n",
    "dbs=all_dbs.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8099c8-53e1-4581-9e87-381f5cf90020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append(\"./code/\")\n",
    "#import func\n",
    "\n",
    "embedding_endpoint_name=\"bge-zh-15-2023-09-25-07-02-01-080-endpoint\"\n",
    "##########embedding by llm model##############\n",
    "sentense_vectors = []\n",
    "sentense_vectors=get_vector_by_sm_endpoint(querys,sm_client,embedding_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a20d5-fdd0-4be2-835d-8afc753062a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs=[]\n",
    "for index, sentence_vector in enumerate(sentense_vectors):\n",
    "    #print(index, sentence_vector)\n",
    "    doc = {\n",
    "        \"metadata_type\":\"table\",\n",
    "        \"database_name\":dbs[index],\n",
    "        \"table_name\": tables[index],\n",
    "        \"query_desc_text\":querys[index],\n",
    "        \"query_desc_embedding\": sentence_vector\n",
    "          }\n",
    "    docs.append(doc)\n",
    "\n",
    "#print((doc[\"database_name\"]))\n",
    "#########ingestion into aos ###################\n",
    "k_nn_ingestion_by_aos(docs,index_name,aos_endpoint,username,passwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98b6e5-4ee6-4749-8aa5-c7c8a48b95ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2:自定义Agent ，定制tools\n",
    "* 自定义AOS倒排及knn检索tools    \n",
    "* 自定义中文Sql Agent 的ReAct prompt 前缀   \n",
    "* 定制CustomerizedSqlDatabaseChain作为db tools做数据库交互\n",
    "* 将db tools加入之前定义的元数据召回的tools列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "beac4e51-32b7-460f-adee-b20151163e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.tools.base import BaseTool, Tool, tool\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from typing import Optional, Type\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    "    CallbackManagerForChainRun\n",
    ")\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "            hosts=[{'host': aos_endpoint, 'port': 443}],\n",
    "            http_auth = pwdauth,\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            connection_class=RequestsHttpConnection)\n",
    "aos_index=\"metadata-index\"\n",
    "\n",
    "\"\"\"Opensearch 向量检索.\"\"\"\n",
    "def customEmbeddingSearch(query: str) -> str:\n",
    "    start = time.time()\n",
    "    query_embedding = get_vector_by_sm_endpoint(query, sm_client, embedding_endpoint_name)\n",
    "    elpase_time = time.time() - start\n",
    "    #print(f'runing time of opensearch_knn : {elpase_time}s seconds')\n",
    "    responses = aos_knn_search(aos_client, \"query_desc_embedding\",query_embedding[0], aos_index, size=10)\n",
    "    return \"The database table is \"+responses[0][\"table_name\"].strip()\n",
    "    #return responses[0][\"table_name\"] \n",
    "    #return \"表名是 \"+responses[0][\"table_name\"].strip()\n",
    "\n",
    "\"\"\"Opensearch 标签检索.\"\"\"\n",
    "def customReverseIndexSearch(query: str) -> str:\n",
    "    start = time.time()\n",
    "    opensearch_query_response = aos_reverse_search(aos_client, aos_index, \"query_desc_text\", query)\n",
    "    elpase_time = time.time() - start\n",
    "    #print(f'runing time of opensearch_query : {elpase_time}s seconds')\n",
    "    return \"The database table is \"+opensearch_query_response[0][\"table_name\"].strip()\n",
    "    #return opensearch_query_response[0][\"table_name\"] \n",
    "    #return \"表名是 \"+opensearch_query_response[0][\"table_name\"].strip()\n",
    "\n",
    " \n",
    "db = SQLDatabase.from_uri(\n",
    "    \"mysql+pymysql://admin:admin12345678@database-us-west-2-demo.cluster-c1qvx9wzmmcz.us-west-2.rds.amazonaws.com/llm\",\n",
    "    sample_rows_in_table_info=0)    \n",
    "    \n",
    "class CustomerizedSQLDatabaseChain(SQLDatabaseChain):\n",
    "    \n",
    "    def _call(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
    "        input_text = f\"{inputs[self.input_key]}\\nSQLQuery:\"\n",
    "        _run_manager.on_text(input_text, verbose=self.verbose)\n",
    "        # If not present, then defaults to None which is all tables.\n",
    "        table_names_to_use = inputs.get(\"table_names_to_use\")\n",
    "        if table_names_to_use is None:\n",
    "            table_names_to_use=self.database._include_tables\n",
    "            print(\"table_names_to_use==\")\n",
    "            print(table_names_to_use)\n",
    "        table_info = self.database.get_table_info(table_names=table_names_to_use)\n",
    "        \n",
    "        llm_inputs = {\n",
    "            \"input\": input_text,\n",
    "            \"top_k\": str(self.top_k),\n",
    "            \"dialect\": self.database.dialect,\n",
    "            \"table_info\": table_info,\n",
    "            #\"stop\": [\"\\nSQLResult:\"],\n",
    "        }\n",
    "        intermediate_steps: List = []\n",
    "        try:\n",
    "            intermediate_steps.append(llm_inputs)  # input: sql generation\n",
    "            sql_cmd = self.llm_chain.predict(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **llm_inputs,\n",
    "            ).strip()\n",
    "            print(\"orginal sql_cmd==\"+sql_cmd)\n",
    "            if self.return_sql:\n",
    "                return {self.output_key: sql_cmd}\n",
    "            if not self.use_query_checker:\n",
    "                _run_manager.on_text(sql_cmd, color=\"green\", verbose=self.verbose)\n",
    "                intermediate_steps.append(\n",
    "                    sql_cmd\n",
    "                )  # output: sql generation (no checker)\n",
    "                #########定制sqlcoder 模型输出##############\n",
    "                pattern = r\"SQLQuery: (.*?)\\n\"\n",
    "                matches = re.findall(pattern, sql_cmd)\n",
    "                match = matches[1]\n",
    "                sql_cmd = match\n",
    "                #print(\"query sql==\"+sql_cmd) \n",
    "                \n",
    "                intermediate_steps.append({\"sql_cmd\": sql_cmd})  # input: sql exec\n",
    "                result = self.database.run(sql_cmd)\n",
    "                intermediate_steps.append(str(result))  # output: sql exec\n",
    "            else:\n",
    "                query_checker_prompt = self.query_checker_prompt or PromptTemplate(\n",
    "                    template=QUERY_CHECKER, input_variables=[\"query\", \"dialect\"]\n",
    "                )\n",
    "                query_checker_chain = LLMChain(\n",
    "                    llm=self.llm_chain.llm, prompt=query_checker_prompt\n",
    "                )\n",
    "                query_checker_inputs = {\n",
    "                    \"query\": sql_cmd,\n",
    "                    \"dialect\": self.database.dialect,\n",
    "                }\n",
    "                checked_sql_command: str = query_checker_chain.predict(\n",
    "                    callbacks=_run_manager.get_child(), **query_checker_inputs\n",
    "                ).strip()\n",
    "                intermediate_steps.append(\n",
    "                    checked_sql_command\n",
    "                )  # output: sql generation (checker)\n",
    "                _run_manager.on_text(\n",
    "                    checked_sql_command, color=\"green\", verbose=self.verbose\n",
    "                )\n",
    "                intermediate_steps.append(\n",
    "                    {\"sql_cmd\": checked_sql_command}\n",
    "                )  # input: sql exec\n",
    "                result = self.database.run(checked_sql_command)\n",
    "                intermediate_steps.append(str(result))  # output: sql exec\n",
    "                sql_cmd = checked_sql_command\n",
    "\n",
    "            _run_manager.on_text(\"\\nSQLResult: \", verbose=self.verbose)\n",
    "            _run_manager.on_text(result, color=\"yellow\", verbose=self.verbose)\n",
    "            # If return direct, we just set the final result equal to\n",
    "            # the result of the sql query result, otherwise try to get a human readable\n",
    "            # final answer\n",
    "            if self.return_direct:\n",
    "                final_result = result\n",
    "            else:\n",
    "                _run_manager.on_text(\"\\nAnswer:\", verbose=self.verbose)\n",
    "                input_text += f\"{sql_cmd}\\nSQLResult: {result}\\nAnswer:\"\n",
    "                llm_inputs[\"input\"] = input_text\n",
    "                intermediate_steps.append(llm_inputs)  # input: final answer\n",
    "                final_result = self.llm_chain.predict(\n",
    "                    callbacks=_run_manager.get_child(),\n",
    "                    **llm_inputs,\n",
    "                ).strip()\n",
    "                intermediate_steps.append(final_result)  # output: final answer\n",
    "                _run_manager.on_text(final_result, color=\"green\", verbose=self.verbose)\n",
    "            chain_result: Dict[str, Any] = {self.output_key: final_result}\n",
    "            if self.return_intermediate_steps:\n",
    "                chain_result[INTERMEDIATE_STEPS_KEY] = intermediate_steps\n",
    "            return chain_result\n",
    "        except Exception as exc:\n",
    "            # Append intermediate steps to exception, to aid in logging and later\n",
    "            # improvement of few shot prompt seeds\n",
    "            exc.intermediate_steps = intermediate_steps  # type: ignore\n",
    "            raise exc\n",
    "\n",
    "def run_query(query):\n",
    "    infos=\"\"\n",
    "    table_name=\"\"\n",
    "    question=\"\"\n",
    "    ####post process agent action output######\n",
    "    if \"\\n\" in query:\n",
    "        infos = query.split(\"\\n\")\n",
    "    elif \",\" in query:\n",
    "        infos = query.split(\",\") \n",
    "\n",
    "    if \":\" in infos[0]:\n",
    "        table_name=infos[0].split(\":\")[1]\n",
    "    else:\n",
    "        table_name=infos[0]\n",
    "    \n",
    "    if \":\" in infos[1]:\n",
    "        question=infos[1].split(\":\")[1]\n",
    "    else:\n",
    "        question=infos[1]\n",
    "    \n",
    "    table_name=table_name.strip()\n",
    "    question=question.strip()\n",
    "    \n",
    "    db_chain = CustomerizedSQLDatabaseChain.from_llm(sm_sql_llm, db, verbose=True, return_sql=True,return_intermediate_steps=False)\n",
    "\n",
    "    if table_name is not None:\n",
    "        db_chain.database._include_tables=[table_name]\n",
    "    response=db_chain.run(question)\n",
    "    return response\n",
    "\n",
    "\n",
    "custom_tool_list=[\n",
    "    Tool.from_function(\n",
    "        func=customReverseIndexSearch,\n",
    "        name=\"reverse index search\",\n",
    "        description=\"use for keywords search to get the database table name\"\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=customEmbeddingSearch,\n",
    "        name=\"embedding knn search\",\n",
    "        description=\"use for semantic level search to get the database table name\"\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        name=\"db utility\",\n",
    "        func=run_query,\n",
    "        description=\"\"\"use for generate sql statement\"\"\"\n",
    "    )]\n",
    "\n",
    "#reverseIndexSearchTool=CustomReverseIndexSearchTool()\n",
    "#embeddingSearchTool=CustomEmbeddingSearchTool()\n",
    "\n",
    "#custom_tool_list=[]\n",
    "#custom_tool_list=[CustomReverseIndexSearchTool(),CustomEmbeddingSearchTool()]\n",
    "#custom_tool_list.append(\n",
    "#   Tool.from_function(\n",
    "#        name=\"Db Querying Tool\",\n",
    "#        func=run_query,\n",
    "#        description=\"\"\"用于数据库交互及生成sql\"\"\"\n",
    "#    ))\n",
    "\n",
    "\n",
    "#print(custom_tool_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b1aa2-f9e5-4af6-bdf1-b96d62deea93",
   "metadata": {},
   "source": [
    "* langchain sm endpoint设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46e4d2a6-03c5-40a1-81d6-a6e8b095ceb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "### for llama2\n",
    "class TextGenContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": model_kwargs\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"generated_text\"]\n",
    "\n",
    "\n",
    "content_hander=TextGenContentHandler()\n",
    "\n",
    "sm_llm=SagemakerEndpoint(\n",
    "        endpoint_name=\"tgi-llama2-2023-09-27-14-25-28-609-endpoint\",\n",
    "        region_name=\"us-west-2\", \n",
    "        model_kwargs=parameters,\n",
    "        content_handler=content_hander\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dcdf15-202c-4c30-8467-60623648c346",
   "metadata": {},
   "source": [
    "* initial bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1229299f-2607-4206-bd35-0c8257126e90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "  Using profile: default\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "    runtime: Optional[bool] = True,\n",
    "):\n",
    "  \n",
    "    if region is None:\n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "        \n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    client_kwargs[\"aws_access_key_id\"] = os.environ.get(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "    client_kwargs[\"aws_secret_access_key\"] = os.environ.get(\"AWS_SECRET_ACCESS_KEY\",\"\")\n",
    "    \n",
    "    bedrock_client = session.client(\n",
    "        service_name=service_name,\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client\n",
    "\n",
    "\n",
    "\n",
    "## for aksk bedrock\n",
    "def get_bedrock_aksk(secret_name='chatbot_bedrock', region_name = \"us-west-2\"):\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = json.loads(get_secret_value_response['SecretString'])\n",
    "    return secret['BEDROCK_ACCESS_KEY'],secret['BEDROCK_SECRET_KEY']\n",
    "\n",
    "ACCESS_KEY, SECRET_KEY=get_bedrock_aksk()\n",
    "\n",
    "###aksk intial client#######\n",
    "#boto3_bedrock = boto3.client(\n",
    "#    service_name=\"bedrock\",\n",
    "#    region_name=\"us-west-2\",\n",
    "#    endpoint_url=\"https://bedrock.us-west-2.amazonaws.com\",\n",
    "#    aws_access_key_id=\"\",\n",
    "#    aws_secret_access_key=\"*******\"\n",
    "#)\n",
    "\n",
    "#role based initial client#######\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"  # E.g. \"us-east-1\"\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\"\n",
    "#os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\"  # E.g. \"arn:aws:...\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=ACCESS_KEY\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=SECRET_KEY\n",
    "\n",
    "\n",
    "#新boto3 sdk只能session方式初始化bedrock\n",
    "boto3_bedrock = get_bedrock_client(\n",
    "    #assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "\n",
    "parameters_bedrock = {\n",
    "    \"max_tokens_to_sample\": 2048,\n",
    "    #\"temperature\": 0.5,\n",
    "    \"temperature\": 0,\n",
    "    #\"top_k\": 250,\n",
    "    #\"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "bedrock_llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs=parameters_bedrock)\n",
    "###test the bedrock langchain integration###\n",
    "#bedrock_llm.predict(\"Human:how do you describe LLM?\\n\"+\n",
    "#           \"Assistant:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a09af-771f-4a63-9ebc-b4326cb7d02b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.0 sqlAgent 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b631652-e3bb-433f-859b-ba9670e5eea0",
   "metadata": {},
   "source": [
    "* 使用langchain sqlAgent\n",
    "* 初始化agent并执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bb9d4-f456-4b71-bedb-5f8e390de36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####目前SqlAgent只支持OpenAI Function类型，不适合SM endpoint######\n",
    "#toolkit = SQLDatabaseToolkit(db=db, llm=sm_sql_llm)\n",
    "\n",
    "#custom_suffix = \"\"\"\n",
    "#我应该先利用标签检索工具，找到具体的数据库和表名，\n",
    "#如果找不到，则利用向量检索工具查找，\n",
    "#然后使用数据库工具查看我刚才找到的应该查询的库和表的详细schema元数据。\n",
    "#\"\"\"\n",
    "#agent = create_sql_agent(llm=sm_llm,\n",
    "#                         toolkit=toolkit,\n",
    "#                         verbose=True,\n",
    "#                         agent_type=AgentType.SELF_ASK_WITH_SEARCH,\n",
    "#                         extra_tools=custom_tool_list,\n",
    "#                         suffix=custom_suffix\n",
    "#                        )\n",
    "#print(agent.agent.llm_chain.prompt.template)\n",
    "#agent.run({\"input\":\"我需要知道销售报表中，下单金额最大的客户id\",\"agent_scratchpad\":\"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf8dfb-6487-4679-bd40-ec2d1d6693d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 PlannerAndExecutor agent type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fb3ec-2eb0-483a-8c88-1bbd06781488",
   "metadata": {
    "tags": []
   },
   "source": [
    "* 使用llm chain做chat的planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81c9e6f8-95fe-42ec-8ddb-b6e0658676ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Any, Dict, List, Optional\n",
    "from pydantic import Extra\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.prompts.base import BasePromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain.agents.tools import Tool\n",
    "from typing import Optional, List, Any\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "class BedrockModelWrapper(Bedrock):\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        prompt = \"\\n\\nHuman: \\n\" + prompt + \"\\n\\nAssistant:\"   ## Satisfy Bedrock-Claude prompt requirements\n",
    "        print(\"prompt===\"+prompt)\n",
    "        return super()._call(prompt, stop, run_manager, **kwargs)\n",
    "\n",
    "\n",
    "sql_prompt_template = \"\"\"\n",
    "You are a MySQL expert. Given an input question, first create a syntactically correct MySql query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per MySQL. \n",
    "You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
    "\n",
    "Use the following format:\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Question: {question}\n",
    "SQLQuery:\n",
    "\"\"\"\n",
    "bedrock_llm_additional = BedrockModelWrapper(model_id=\"anthropic.claude-v2\", \n",
    "                                          client=boto3_bedrock, \n",
    "                                          model_kwargs=parameters_bedrock)\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "\n",
    "def build_chat_chain():\n",
    "    conversation_with_summary_chain = ConversationChain(\n",
    "        llm=bedrock_llm_additional, \n",
    "        verbose=True\n",
    "    )\n",
    "    return conversation_with_summary_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea0f676-5fee-40a7-a1e1-71aef0af09cc",
   "metadata": {},
   "source": [
    "* 使用llm chain做chat的planner\n",
    "* 使用langchain plannerAndExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b00cf-8fcd-445f-82db-4b0d019096a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "combo_template = \"\"\"\n",
    "先了解问题并制定解决问题的计划。\n",
    "请输出以标题\"plan:\"开头的计划，然后输出步骤的编号列表。在计划步骤时，不要使用过去的对话历史记录。\n",
    "请将计划制定为准确完成任务所需的最少步骤数。\n",
    "\n",
    "以下是使用工具解决任务的步骤，请严格遵守：\n",
    "先使用\"reverse index search\" 标签检索工具查找输入问题。\n",
    "如果结果为空，则使用\"embedding knn search\" 向量检索工具查找输入问题。\n",
    "然后使用\"db Querying Tool\" 数据库工具执行上一步骤结果输出。\n",
    "最后返回结果。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "combo_template = \"\"\"\n",
    "First understand the problem and devise a plan to solve the problem. \n",
    "Please output the plan starting with the header 'Plan:' and then followed by a numbered list of steps. Do not use past conversation history when you are planning the steps.\n",
    "Please make the plan the minimum number of steps required to accurately complete the task. \n",
    "\n",
    "\n",
    "These are guidance on when to use a tool to solve a task, follow them strictly:\n",
    "\n",
    "first use \"reverse index search\" tool to get database table name base on user's original problem\n",
    "if previously step not return anyting，then use \"embedding knn search\" tool to get database table name base on user's original problem\n",
    "then use the \"db utility\" tool to generate the sql statement, use that database table name which previously step returns and user's original problem\n",
    "\n",
    "DO NOT GENERATE SQL STATEMENT YOURSELF,ONLY USE TOOL TO DO.\n",
    "DO NOT CREATE STEPS THAT ARE NOT NEEDED TO SOLVE A TASK.     \n",
    "Once you have answers for the question, stop and provide the final answers. The final answers should be a combination of the answers to all the questions, not just the last one.\n",
    "\n",
    "Please make sure you have a plan to answer all the questions in the input, not just the last one. \n",
    "Please use these to construct an answer to the question , as though you were answering the question directly. Ensure that your answer is accurate and doesn’t contain any information not directly supported by the summary and quotes. \n",
    "If there are no data or information in this document that seem relevant to this question, please just say \"I can’t find any relevant quotes\". \n",
    "\"\"\"\n",
    "\n",
    "planner = load_chat_planner(bedrock_llm_additional)\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(combo_template)\n",
    "human_message_prompt = planner.llm_chain.prompt.messages[1]\n",
    "\n",
    "planner.llm_chain.prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "print(planner.llm_chain.prompt)\n",
    "executor = load_agent_executor(bedrock_llm_additional, custom_tool_list, verbose=True)\n",
    "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True, max_iterations=3,memory=memory)\n",
    "\n",
    "\n",
    "output = agent({\"input\":\"最近一个月温度合格的派车单数量\"})\n",
    "#output = agent({\"input\":\"what's the number of qualified temperature delivery orders in the last month\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe257e6-cdf8-4f9f-8ba9-1ba2016fb84f",
   "metadata": {},
   "source": [
    "* clearup agent and executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb11b5-1907-4dc0-b371-3ff57d0f55dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del executor\n",
    "del agent\n",
    "del planner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55441f09-db95-4339-b4c1-b3d1076c8055",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Conversationval Zero Shot Agent type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1016d-96af-460e-9873-3857997514ce",
   "metadata": {},
   "source": [
    "* Set up the base template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c048aad-7cf0-4da5-a34c-2447324d424a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "import re\n",
    "flexible_tools_guide=\"\"\"\n",
    " - use \"reverse index search\" tool to get table name if need to search for table name by keywords\n",
    " - use \"embedding knn search\" tool to get table name if need to search for table name by semantic level\n",
    " - use \"db utility\" tool to generate sql query based on orignal question\n",
    " - use tool to generate sql query, Do Not generate sql query yourself\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "strict_tools_guide=\"\"\"\n",
    " - first use \"reverse index search\" tool to get table name \n",
    " - if previously step does not return anyting，then use \"embedding knn search\" tool to get table name \n",
    " - if previously step still can't return anyting, say \"I can't find the answer for this question.\" \n",
    " - otherwise use \"db utility\" tool to generate database sql using table name which previously step return, and original question\n",
    "\"\"\"\n",
    "\n",
    "# Set up the base template\n",
    "template = \"\"\"Answer the following questions as best you can.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "\n",
    "These are guidance on when to use a tool to solve a task, follow them strictly:\n",
    " - use \"reverse index search\" tool to get database table name if need to search for table name by keywords\n",
    " - use \"embedding knn search\" tool to get database table name if need to search for table name by semantic level\n",
    " - use \"db utility\" tool to generate database sql statement\n",
    " - use tool to generate sql statement, DO NOT GENERATE SQL STATEMENT YOURSELF\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation:\n",
    "the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "\n",
    "Begin! \n",
    "\n",
    "Previous conversation history:\n",
    "{history}\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "simple_react_prompt=\"\"\"Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, Also try to follow steps mentioned above\n",
    "Action: the action to take, should be one of [\"reverse index search\", \"embedding knn search\"]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "These are guidance on when to use a tool to solve a task, follow them strictly:\n",
    " - use \"reverse index search\" tool to get database table name if need to search for table name by keywords\n",
    " - use \"embedding knn search\" tool to get database table name if need to search for table name by semantic level\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Assistant:\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853fbbc0-77f4-4448-838b-7460596eea32",
   "metadata": {},
   "source": [
    "* Set up customerized templateFormat\n",
    "* Set up customerized outputParse to get individual tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27715e31-5710-490e-87ca-65d6c2f5d703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        final_prompt = \"Human:\"+self.template.format(**kwargs)+\"\\nAssistant:\"\n",
    "        return final_prompt\n",
    "        #return self.template.format(**kwargs)\n",
    "    \n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=custom_tool_list,\n",
    "    input_variables=[\"input\", \"intermediate_steps\",\"history\"]\n",
    ")\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        #print(\"cur step's llm_output ===\"+llm_output)\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf5f48-b18b-439e-b322-7e66a230c344",
   "metadata": {
    "tags": []
   },
   "source": [
    "* add chat memeory\n",
    "* Set up the agent\n",
    "* Run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f1bffec-9a66-432d-8e6b-3cbf2878a363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Thought: The question is asking for table names related to \"the number of delivery orders with qualified temperature in the past month\". I should first analyze the key entities - \"delivery orders\", \"temperature\", \"past month\".\n",
      "\n",
      "Action: reverse index search\n",
      "Action Input: delivery orders, temperature, past month\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe database table is ads_bi_quality_monitor_shipping_detail\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The reverse index search found the relevant table name ads_bi_quality_monitor_shipping_detail. Now I need to generate the SQL based on this table and the original question.\n",
      "\n",
      "Action: Generate SQL\n",
      "Action Input: \n",
      "ads_bi_quality_monitor_shipping_detail, '最近一个月温度合格的派车单数量'\u001b[0m\n",
      "Observation: Generate SQL is not a valid tool, try one of [reverse index search, embedding knn search, db utility].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use a database utility tool to generate the SQL based on the table name and original question.\n",
      "\n",
      "Action: db utility \n",
      "Action Input: \n",
      "Table: ads_bi_quality_monitor_shipping_detail\n",
      "Question: '最近一个月温度合格的派车单数量'\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new CustomerizedSQLDatabaseChain chain...\u001b[0m\n",
      "'最近一个月温度合格的派车单数量'\n",
      "SQLQuery:table_names_to_use==\n",
      "['ads_bi_quality_monitor_shipping_detail']\n",
      "orginal sql_cmd==You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\n",
      "CREATE TABLE ads_bi_quality_monitor_shipping_detail (\n",
      "\tshipping_order_code VARCHAR(100) COMMENT '派车单编码', \n",
      "\tlicense_plate VARCHAR(100) COMMENT '车牌号', \n",
      "\ttruck_type VARCHAR(50) COMMENT '车辆类型', \n",
      "\ttenant_id VARCHAR(100) COMMENT '租户编码', \n",
      "\ttenant_name VARCHAR(200) COMMENT '租户名称', \n",
      "\tfather_company_code VARCHAR(100) COMMENT '分子公司编码', \n",
      "\tfather_company_name VARCHAR(200) COMMENT '分子公司名称', \n",
      "\tfather_company_short_name VARCHAR(200) COMMENT '分子公司简称', \n",
      "\tstart_transport_time VARCHAR(50) COMMENT '运输出发时间', \n",
      "\tsigning_time VARCHAR(50) COMMENT '派车单签收时间', \n",
      "\tplan_start_time VARCHAR(50) COMMENT '派车单计划取货时间', \n",
      "\tplan_end_time VARCHAR(50) COMMENT '派车单计划送达时间', \n",
      "\tfrist_fence_time VARCHAR(50) COMMENT '第一次碰撞装货地电子围栏时间', \n",
      "\tleave_load_station_2km_time VARCHAR(50) COMMENT '离开最后一个装货地电子围栏2km的时间', \n",
      "\tfrist_arrive_unload_time VARCHAR(50) COMMENT '首次到达卸货点电子围栏时间', \n",
      "\ttransport_type VARCHAR(10) COMMENT '运输类型(干线/城配)', \n",
      "\tplan_mileage VARCHAR(50) COMMENT '计划里程', \n",
      "\tdriver_accept_time VARCHAR(50) COMMENT '司机接单时间', \n",
      "\tdriver_name VARCHAR(50) COMMENT '司机姓名', \n",
      "\tdriver_phone VARCHAR(50) COMMENT '司机电话', \n",
      "\tdriver_type VARCHAR(10) COMMENT '司机类型', \n",
      "\ttransport_tenant_id VARCHAR(100) COMMENT '运力承运商id', \n",
      "\ttransport_tenant_name VARCHAR(200) COMMENT '运力承运商名称', \n",
      "\twarm_area VARCHAR(50) COMMENT '温区信息', \n",
      "\twaybill_count INTEGER COMMENT '运单数量', \n",
      "\tgps_device_list VARCHAR(100) COMMENT 'gps设备', \n",
      "\tgps_report_dot_num INTEGER COMMENT 'gps上报点数', \n",
      "\ttemp_substandard_min DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)', \n",
      "\ttemp_substandard_min_n12 DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)_-12', \n",
      "\ttemp_substandard_min_n16 DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)_-16', \n",
      "\tshipping_order_transport_min DECIMAL(20, 8) COMMENT '派车单运输总时长(分钟)', \n",
      "\tshipping_order_temp_standard_rate DECIMAL(20, 8) COMMENT '派车单温度达标率', \n",
      "\tshipping_order_temp_standard_rate_n12 DECIMAL(20, 8) COMMENT '派车单温度达标率_-12', \n",
      "\tshipping_order_temp_standard_rate_n16 DECIMAL(20, 8) COMMENT '派车单温度达标率_-16', \n",
      "\tdep_fence_match_num INTEGER COMMENT '出发地电子围栏匹配数量', \n",
      "\tdep_total_num INTEGER COMMENT '出发地总数量', \n",
      "\tdep_fence_match_rate DECIMAL(20, 8) COMMENT '出发地电子围栏匹配率', \n",
      "\tdes_fence_match_num INTEGER COMMENT '目的地电子围栏匹配数量', \n",
      "\tdes_total_num INTEGER COMMENT '目的地总数量', \n",
      "\tdes_fence_match_rate DECIMAL(20, 8) COMMENT '目的地电子围栏匹配率', \n",
      "\texception_shipping_order_type VARCHAR(10) COMMENT '异常派车单情况,0-非异常', \n",
      "\tsettlement_tenant_id VARCHAR(100) COMMENT '结算主体租户id', \n",
      "\tsettlement_tenant_name VARCHAR(100) COMMENT '结算主体租户名称', \n",
      "\ttruck_ownership VARCHAR(100) COMMENT '车辆所有权(自有/外请/临时)', \n",
      "\tload_finish_time VARCHAR(50) COMMENT '派车单点击装货完成时间', \n",
      "\tlast_leave_unload_time VARCHAR(50) COMMENT '最后离开卸货点时间', \n",
      "\ttemp_right_tag VARCHAR(20) COMMENT '温度是否合格(合格/不合格/不参与评估)', \n",
      "\twarm_area_type VARCHAR(20) COMMENT '温区类型。常温/冷链/自定义区间', \n",
      "\tsource_dt VARCHAR(20) COMMENT '派车单来源的增量表dt', \n",
      "\tcur_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '当前派车单对应的客户', \n",
      "\tis_app_operation VARCHAR(10) COMMENT '是否APP操作卡控', \n",
      "\tleave_load_station_time_app VARCHAR(50) COMMENT '离开第一个装货地时间_app', \n",
      "\tfrist_arrive_unload_time_app VARCHAR(50) COMMENT '到达第一个卸货点时间_app', \n",
      "\tlast_arrive_unload_time_app VARCHAR(50) COMMENT '到达最后一个卸货点时间_app', \n",
      "\ttemp_calc_start_time VARCHAR(50) COMMENT '温度计算开始时间', \n",
      "\ttemp_calc_end_time VARCHAR(50) COMMENT '温度计算结束时间', \n",
      "\texception_shipping_order_type_desc VARCHAR(100) COMMENT '异常派车单情况描述', \n",
      "\troot_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '根派车单对应的客户', \n",
      "\tis_use_custom_temp_range VARCHAR(10) COMMENT '是否使用自定义温度范围', \n",
      "\ttemp_eval_lowest INTEGER COMMENT '温度考核最低值', \n",
      "\ttemp_eval_highest INTEGER COMMENT '温度考核最高值', \n",
      "\tis_gps_cover VARCHAR(10) COMMENT 'GPS是否覆盖', \n",
      "\tshipping_create_time VARCHAR(50) COMMENT '派车单创建时间', \n",
      "\tgps_device_list_plan VARCHAR(100) COMMENT 'GPS设备_预估', \n",
      "\tis_gps_cover_plan VARCHAR(10) COMMENT 'GPS是否覆盖_预估', \n",
      "\tfirst_station_is_on_time VARCHAR(10) COMMENT '首店是否准时', \n",
      "\tis_many_warm VARCHAR(10) COMMENT '是否多温区', \n",
      "\tmany_temp_standard_rate DECIMAL(20, 8) COMMENT '多温区温度达标率', \n",
      "\tlc_standard_ratio DECIMAL(20, 8) COMMENT '冷藏温度达标率', \n",
      "\tld_standard_ratio DECIMAL(20, 8) COMMENT '冷冻温度达标率', \n",
      "\tprobe_warm_list TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '探头温区'\n",
      ")DEFAULT CHARSET=utf8 COMMENT='BI看板_品质监控_派车单明细' ENGINE=InnoDB\n",
      "\n",
      "Question: '最近一个月温度合格的派车单数量'\n",
      "SQLQuery: SELECT count(*) FROM ads_bi_quality_monitor_shipping_detail WHERE temp_right_tag = '合格' and DATE_SUB(CURDATE(), INTERVAL 1 MONTH) <= shipping_create_time;\n",
      "\n",
      "The query above counts the number of shipping orders that were temperature-qualified in the last month. The temperature-qualified status is determined by the value of the column temp_right_tag. The date used in the comparison is the current date minus one month. This is because the shipping orders are expected to be created in the last month.\n",
      "\n",
      "The result of this query is a single number, which is the number of temperature-qualified shipping orders in the last month.\n",
      "\n",
      "The query uses a single table, ads_bi_quality_monitor_shipping_detail, which contains information about the quality of the shipping orders. The table has the following columns:\n",
      "\n",
      "shipping_order_code: The unique code assigned to each shipping order.\n",
      "temp_right_tag: The tag indicating whether the temperature of the order is right or not.\n",
      "shipping_create_time: The time when the shipping order was created.\n",
      "\n",
      "The table is partitioned by the column tenant_id, which means that the data for each tenant is stored in a separate partition. This allows the query to run efficiently even if the database contains a large number of tenants.\n",
      "\n",
      "The query does not depend on any other tables or views.\n",
      "\n",
      "---\n",
      "\n",
      "### Response:\n",
      "\n",
      "```\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mYou are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\n",
      "CREATE TABLE ads_bi_quality_monitor_shipping_detail (\n",
      "\tshipping_order_code VARCHAR(100) COMMENT '派车单编码', \n",
      "\tlicense_plate VARCHAR(100) COMMENT '车牌号', \n",
      "\ttruck_type VARCHAR(50) COMMENT '车辆类型', \n",
      "\ttenant_id VARCHAR(100) COMMENT '租户编码', \n",
      "\ttenant_name VARCHAR(200) COMMENT '租户名称', \n",
      "\tfather_company_code VARCHAR(100) COMMENT '分子公司编码', \n",
      "\tfather_company_name VARCHAR(200) COMMENT '分子公司名称', \n",
      "\tfather_company_short_name VARCHAR(200) COMMENT '分子公司简称', \n",
      "\tstart_transport_time VARCHAR(50) COMMENT '运输出发时间', \n",
      "\tsigning_time VARCHAR(50) COMMENT '派车单签收时间', \n",
      "\tplan_start_time VARCHAR(50) COMMENT '派车单计划取货时间', \n",
      "\tplan_end_time VARCHAR(50) COMMENT '派车单计划送达时间', \n",
      "\tfrist_fence_time VARCHAR(50) COMMENT '第一次碰撞装货地电子围栏时间', \n",
      "\tleave_load_station_2km_time VARCHAR(50) COMMENT '离开最后一个装货地电子围栏2km的时间', \n",
      "\tfrist_arrive_unload_time VARCHAR(50) COMMENT '首次到达卸货点电子围栏时间', \n",
      "\ttransport_type VARCHAR(10) COMMENT '运输类型(干线/城配)', \n",
      "\tplan_mileage VARCHAR(50) COMMENT '计划里程', \n",
      "\tdriver_accept_time VARCHAR(50) COMMENT '司机接单时间', \n",
      "\tdriver_name VARCHAR(50) COMMENT '司机姓名', \n",
      "\tdriver_phone VARCHAR(50) COMMENT '司机电话', \n",
      "\tdriver_type VARCHAR(10) COMMENT '司机类型', \n",
      "\ttransport_tenant_id VARCHAR(100) COMMENT '运力承运商id', \n",
      "\ttransport_tenant_name VARCHAR(200) COMMENT '运力承运商名称', \n",
      "\twarm_area VARCHAR(50) COMMENT '温区信息', \n",
      "\twaybill_count INTEGER COMMENT '运单数量', \n",
      "\tgps_device_list VARCHAR(100) COMMENT 'gps设备', \n",
      "\tgps_report_dot_num INTEGER COMMENT 'gps上报点数', \n",
      "\ttemp_substandard_min DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)', \n",
      "\ttemp_substandard_min_n12 DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)_-12', \n",
      "\ttemp_substandard_min_n16 DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)_-16', \n",
      "\tshipping_order_transport_min DECIMAL(20, 8) COMMENT '派车单运输总时长(分钟)', \n",
      "\tshipping_order_temp_standard_rate DECIMAL(20, 8) COMMENT '派车单温度达标率', \n",
      "\tshipping_order_temp_standard_rate_n12 DECIMAL(20, 8) COMMENT '派车单温度达标率_-12', \n",
      "\tshipping_order_temp_standard_rate_n16 DECIMAL(20, 8) COMMENT '派车单温度达标率_-16', \n",
      "\tdep_fence_match_num INTEGER COMMENT '出发地电子围栏匹配数量', \n",
      "\tdep_total_num INTEGER COMMENT '出发地总数量', \n",
      "\tdep_fence_match_rate DECIMAL(20, 8) COMMENT '出发地电子围栏匹配率', \n",
      "\tdes_fence_match_num INTEGER COMMENT '目的地电子围栏匹配数量', \n",
      "\tdes_total_num INTEGER COMMENT '目的地总数量', \n",
      "\tdes_fence_match_rate DECIMAL(20, 8) COMMENT '目的地电子围栏匹配率', \n",
      "\texception_shipping_order_type VARCHAR(10) COMMENT '异常派车单情况,0-非异常', \n",
      "\tsettlement_tenant_id VARCHAR(100) COMMENT '结算主体租户id', \n",
      "\tsettlement_tenant_name VARCHAR(100) COMMENT '结算主体租户名称', \n",
      "\ttruck_ownership VARCHAR(100) COMMENT '车辆所有权(自有/外请/临时)', \n",
      "\tload_finish_time VARCHAR(50) COMMENT '派车单点击装货完成时间', \n",
      "\tlast_leave_unload_time VARCHAR(50) COMMENT '最后离开卸货点时间', \n",
      "\ttemp_right_tag VARCHAR(20) COMMENT '温度是否合格(合格/不合格/不参与评估)', \n",
      "\twarm_area_type VARCHAR(20) COMMENT '温区类型。常温/冷链/自定义区间', \n",
      "\tsource_dt VARCHAR(20) COMMENT '派车单来源的增量表dt', \n",
      "\tcur_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '当前派车单对应的客户', \n",
      "\tis_app_operation VARCHAR(10) COMMENT '是否APP操作卡控', \n",
      "\tleave_load_station_time_app VARCHAR(50) COMMENT '离开第一个装货地时间_app', \n",
      "\tfrist_arrive_unload_time_app VARCHAR(50) COMMENT '到达第一个卸货点时间_app', \n",
      "\tlast_arrive_unload_time_app VARCHAR(50) COMMENT '到达最后一个卸货点时间_app', \n",
      "\ttemp_calc_start_time VARCHAR(50) COMMENT '温度计算开始时间', \n",
      "\ttemp_calc_end_time VARCHAR(50) COMMENT '温度计算结束时间', \n",
      "\texception_shipping_order_type_desc VARCHAR(100) COMMENT '异常派车单情况描述', \n",
      "\troot_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '根派车单对应的客户', \n",
      "\tis_use_custom_temp_range VARCHAR(10) COMMENT '是否使用自定义温度范围', \n",
      "\ttemp_eval_lowest INTEGER COMMENT '温度考核最低值', \n",
      "\ttemp_eval_highest INTEGER COMMENT '温度考核最高值', \n",
      "\tis_gps_cover VARCHAR(10) COMMENT 'GPS是否覆盖', \n",
      "\tshipping_create_time VARCHAR(50) COMMENT '派车单创建时间', \n",
      "\tgps_device_list_plan VARCHAR(100) COMMENT 'GPS设备_预估', \n",
      "\tis_gps_cover_plan VARCHAR(10) COMMENT 'GPS是否覆盖_预估', \n",
      "\tfirst_station_is_on_time VARCHAR(10) COMMENT '首店是否准时', \n",
      "\tis_many_warm VARCHAR(10) COMMENT '是否多温区', \n",
      "\tmany_temp_standard_rate DECIMAL(20, 8) COMMENT '多温区温度达标率', \n",
      "\tlc_standard_ratio DECIMAL(20, 8) COMMENT '冷藏温度达标率', \n",
      "\tld_standard_ratio DECIMAL(20, 8) COMMENT '冷冻温度达标率', \n",
      "\tprobe_warm_list TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '探头温区'\n",
      ")DEFAULT CHARSET=utf8 COMMENT='BI看板_品质监控_派车单明细' ENGINE=InnoDB\n",
      "\n",
      "Question: '最近一个月温度合格的派车单数量'\n",
      "SQLQuery: SELECT count(*) FROM ads_bi_quality_monitor_shipping_detail WHERE temp_right_tag = '合格' and DATE_SUB(CURDATE(), INTERVAL 1 MONTH) <= shipping_create_time;\n",
      "\n",
      "The query above counts the number of shipping orders that were temperature-qualified in the last month. The temperature-qualified status is determined by the value of the column temp_right_tag. The date used in the comparison is the current date minus one month. This is because the shipping orders are expected to be created in the last month.\n",
      "\n",
      "The result of this query is a single number, which is the number of temperature-qualified shipping orders in the last month.\n",
      "\n",
      "The query uses a single table, ads_bi_quality_monitor_shipping_detail, which contains information about the quality of the shipping orders. The table has the following columns:\n",
      "\n",
      "shipping_order_code: The unique code assigned to each shipping order.\n",
      "temp_right_tag: The tag indicating whether the temperature of the order is right or not.\n",
      "shipping_create_time: The time when the shipping order was created.\n",
      "\n",
      "The table is partitioned by the column tenant_id, which means that the data for each tenant is stored in a separate partition. This allows the query to run efficiently even if the database contains a large number of tenants.\n",
      "\n",
      "The query does not depend on any other tables or views.\n",
      "\n",
      "---\n",
      "\n",
      "### Response:\n",
      "\n",
      "```\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent stopped due to iteration limit or time limit.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "output_parser = CustomOutputParser()\n",
    "tool_names = [tool.name for tool in custom_tool_list]\n",
    "\n",
    "####simple react agent####################\n",
    "agent_executor = initialize_agent(custom_tool_list, bedrock_llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                                  verbose=True,max_iterations=3,\n",
    "                                  #agent_kwargs={\"output_parser\":output_parser,\"stop\":[\"\\nObservation:\"]}\n",
    "                                 )\n",
    "agent_executor.agent.llm_chain.prompt.template=simple_react_prompt\n",
    "agent_executor.run(\"\\n\\nHuman:检索'最近一个月温度合格的派车单数量'这个问题涉及的表名，并根据这个表名和'最近一个月温度合格的派车单数量'的问题，使用数据库工具生成sql\\n\")\n",
    "#query=\"\"\"\\n\\nHuman:search the database table name related to the question of 'Number of qualified temperature delivery orders in the last month', and generate sql statement use the 'db utility' tool based on that table name and the original question\\n\"\"\"\n",
    "#agent_executor.run(query)\n",
    "\n",
    "\n",
    "####more flexible customerized agent#####\n",
    "#memory=ConversationBufferWindowMemory(k=3)\n",
    "#llm_chain = LLMChain(llm=bedrock_llm, prompt=prompt)\n",
    "#agent = LLMSingleActionAgent(\n",
    "#    llm_chain=llm_chain,\n",
    "#    output_parser=output_parser,\n",
    "#    stop=[\"\\nObservation:\"],\n",
    "#    allowed_tools=tool_names\n",
    "#)\n",
    "#agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=custom_tool_list,max_iterations=6,verbose=True,handle_parsing_errors=True, memory=memory)\n",
    "\n",
    "\n",
    "#output=agent_executor.run(\"'最近一个月温度合格的派车单数量'这个问题涉及的表名是什么？\")\n",
    "#print(output)\n",
    "#output=agent_executor.run(\"根据刚才的表名和‘最近一个月温度合格的派车单数量’这个问题，使用数据库工具生成sql\")\n",
    "#print(output)\n",
    "#agent_executor.run(\"检索'最近一个月温度合格的派车单数量'这个问题的数据库表名字，并根据这个数据库表名字和刚才的原始问题，使用数据库工具生成sql语句\")\n",
    "\n",
    "## prompt in english\n",
    "#query=\"\"\"search the database table name related to the question of 'Number of qualified temperature delivery orders in the last month', and generate sql statement use the 'db utility' tool based on that table name and the question of 'Number of qualified temperature delivery orders in the last month'\"\"\"\n",
    "#agent_executor.run(query)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a267c7e-d2d0-40f1-9cea-712f5741c414",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.4 agent只处理意图识别，直接调用SqlDatabaseChain执行sql生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6e1184d9-35e4-4645-ad51-47d50014a386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m 让我思考一下这个问题涉及的数据库表名。\n",
      "\n",
      "Thought: 根据问题描述,这个问题需要查询最近一个月内温度合格的派车单数量。为了得到这个信息,我需要先理解问题涉及的关键信息点:\n",
      "1. 时间范围 - 最近一个月\n",
      "2. 派车单信息 \n",
      "3. 温度合格条件\n",
      "\n",
      "根据这些信息点,我判断这个问题需要连接派车单表和温度表,并以时间为条件进行过滤。而派车单信息一般存储在订单表或派车单表中。\n",
      "\n",
      "Action: embedding knn search\n",
      "Action Input: 最近一个月温度合格的派车单数量 数据库表名\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe database table is ads_bi_quality_monitor_shipping_detail\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 通过语义相似性搜索,我找到这个问题涉及的数据库表名是 ads_bi_quality_monitor_shipping_detail。\n",
      "\n",
      "Final Answer: 这个问题涉及的数据库表名是 ads_bi_quality_monitor_shipping_detail\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"\\n\\nHuman:'最近一个月温度合格的派车单数量'这个问题涉及的数据库表名是什么？\", 'output': '这个问题涉及的数据库表名是 ads_bi_quality_monitor_shipping_detail'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CustomerizedSQLDatabaseChain chain...\u001b[0m\n",
      "最近一个月温度合格的派车单数量\n",
      "SQLQuery:table_names_to_use==\n",
      "{'ads_bi_quality_monitor_shipping_detail'}\n",
      "orginal sql_cmd==You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\n",
      "CREATE TABLE ads_bi_quality_monitor_shipping_detail (\n",
      "\tshipping_order_code VARCHAR(100) COMMENT '派车单编码', \n",
      "\tlicense_plate VARCHAR(100) COMMENT '车牌号', \n",
      "\ttruck_type VARCHAR(50) COMMENT '车辆类型', \n",
      "\ttenant_id VARCHAR(100) COMMENT '租户编码', \n",
      "\ttenant_name VARCHAR(200) COMMENT '租户名称', \n",
      "\tfather_company_code VARCHAR(100) COMMENT '分子公司编码', \n",
      "\tfather_company_name VARCHAR(200) COMMENT '分子公司名称', \n",
      "\tfather_company_short_name VARCHAR(200) COMMENT '分子公司简称', \n",
      "\tstart_transport_time VARCHAR(50) COMMENT '运输出发时间', \n",
      "\tsigning_time VARCHAR(50) COMMENT '派车单签收时间', \n",
      "\tplan_start_time VARCHAR(50) COMMENT '派车单计划取货时间', \n",
      "\tplan_end_time VARCHAR(50) COMMENT '派车单计划送达时间', \n",
      "\tfrist_fence_time VARCHAR(50) COMMENT '第一次碰撞装货地电子围栏时间', \n",
      "\tleave_load_station_2km_time VARCHAR(50) COMMENT '离开最后一个装货地电子围栏2km的时间', \n",
      "\tfrist_arrive_unload_time VARCHAR(50) COMMENT '首次到达卸货点电子围栏时间', \n",
      "\ttransport_type VARCHAR(10) COMMENT '运输类型(干线/城配)', \n",
      "\tplan_mileage VARCHAR(50) COMMENT '计划里程', \n",
      "\tdriver_accept_time VARCHAR(50) COMMENT '司机接单时间', \n",
      "\tdriver_name VARCHAR(50) COMMENT '司机姓名', \n",
      "\tdriver_phone VARCHAR(50) COMMENT '司机电话', \n",
      "\tdriver_type VARCHAR(10) COMMENT '司机类型', \n",
      "\ttransport_tenant_id VARCHAR(100) COMMENT '运力承运商id', \n",
      "\ttransport_tenant_name VARCHAR(200) COMMENT '运力承运商名称', \n",
      "\twarm_area VARCHAR(50) COMMENT '温区信息', \n",
      "\twaybill_count INTEGER COMMENT '运单数量', \n",
      "\tgps_device_list VARCHAR(100) COMMENT 'gps设备', \n",
      "\tgps_report_dot_num INTEGER COMMENT 'gps上报点数', \n",
      "\ttemp_substandard_min DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)', \n",
      "\ttemp_substandard_min_n12 DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)_-12', \n",
      "\ttemp_substandard_min_n16 DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)_-16', \n",
      "\tshipping_order_transport_min DECIMAL(20, 8) COMMENT '派车单运输总时长(分钟)', \n",
      "\tshipping_order_temp_standard_rate DECIMAL(20, 8) COMMENT '派车单温度达标率', \n",
      "\tshipping_order_temp_standard_rate_n12 DECIMAL(20, 8) COMMENT '派车单温度达标率_-12', \n",
      "\tshipping_order_temp_standard_rate_n16 DECIMAL(20, 8) COMMENT '派车单温度达标率_-16', \n",
      "\tdep_fence_match_num INTEGER COMMENT '出发地电子围栏匹配数量', \n",
      "\tdep_total_num INTEGER COMMENT '出发地总数量', \n",
      "\tdep_fence_match_rate DECIMAL(20, 8) COMMENT '出发地电子围栏匹配率', \n",
      "\tdes_fence_match_num INTEGER COMMENT '目的地电子围栏匹配数量', \n",
      "\tdes_total_num INTEGER COMMENT '目的地总数量', \n",
      "\tdes_fence_match_rate DECIMAL(20, 8) COMMENT '目的地电子围栏匹配率', \n",
      "\texception_shipping_order_type VARCHAR(10) COMMENT '异常派车单情况,0-非异常', \n",
      "\tsettlement_tenant_id VARCHAR(100) COMMENT '结算主体租户id', \n",
      "\tsettlement_tenant_name VARCHAR(100) COMMENT '结算主体租户名称', \n",
      "\ttruck_ownership VARCHAR(100) COMMENT '车辆所有权(自有/外请/临时)', \n",
      "\tload_finish_time VARCHAR(50) COMMENT '派车单点击装货完成时间', \n",
      "\tlast_leave_unload_time VARCHAR(50) COMMENT '最后离开卸货点时间', \n",
      "\ttemp_right_tag VARCHAR(20) COMMENT '温度是否合格(合格/不合格/不参与评估)', \n",
      "\twarm_area_type VARCHAR(20) COMMENT '温区类型。常温/冷链/自定义区间', \n",
      "\tsource_dt VARCHAR(20) COMMENT '派车单来源的增量表dt', \n",
      "\tcur_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '当前派车单对应的客户', \n",
      "\tis_app_operation VARCHAR(10) COMMENT '是否APP操作卡控', \n",
      "\tleave_load_station_time_app VARCHAR(50) COMMENT '离开第一个装货地时间_app', \n",
      "\tfrist_arrive_unload_time_app VARCHAR(50) COMMENT '到达第一个卸货点时间_app', \n",
      "\tlast_arrive_unload_time_app VARCHAR(50) COMMENT '到达最后一个卸货点时间_app', \n",
      "\ttemp_calc_start_time VARCHAR(50) COMMENT '温度计算开始时间', \n",
      "\ttemp_calc_end_time VARCHAR(50) COMMENT '温度计算结束时间', \n",
      "\texception_shipping_order_type_desc VARCHAR(100) COMMENT '异常派车单情况描述', \n",
      "\troot_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '根派车单对应的客户', \n",
      "\tis_use_custom_temp_range VARCHAR(10) COMMENT '是否使用自定义温度范围', \n",
      "\ttemp_eval_lowest INTEGER COMMENT '温度考核最低值', \n",
      "\ttemp_eval_highest INTEGER COMMENT '温度考核最高值', \n",
      "\tis_gps_cover VARCHAR(10) COMMENT 'GPS是否覆盖', \n",
      "\tshipping_create_time VARCHAR(50) COMMENT '派车单创建时间', \n",
      "\tgps_device_list_plan VARCHAR(100) COMMENT 'GPS设备_预估', \n",
      "\tis_gps_cover_plan VARCHAR(10) COMMENT 'GPS是否覆盖_预估', \n",
      "\tfirst_station_is_on_time VARCHAR(10) COMMENT '首店是否准时', \n",
      "\tis_many_warm VARCHAR(10) COMMENT '是否多温区', \n",
      "\tmany_temp_standard_rate DECIMAL(20, 8) COMMENT '多温区温度达标率', \n",
      "\tlc_standard_ratio DECIMAL(20, 8) COMMENT '冷藏温度达标率', \n",
      "\tld_standard_ratio DECIMAL(20, 8) COMMENT '冷冻温度达标率', \n",
      "\tprobe_warm_list TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '探头温区'\n",
      ")DEFAULT CHARSET=utf8 COMMENT='BI看板_品质监控_派车单明细' ENGINE=InnoDB\n",
      "\n",
      "Question: 最近一个月温度合格的派车单数量\n",
      "SQLQuery: SELECT count(*) FROM ads_bi_quality_monitor_shipping_detail WHERE temp_right_tag = '合格' and DATE_SUB(CURDATE(), INTERVAL 1 MONTH) <= shipping_create_time;\n",
      "\n",
      "The query above counts the number of shipping orders that were temperature-qualified in the last month. The temperature-qualified status is determined by the value of the column temp_right_tag. The date used in the comparison is the current date minus one month. This is because the shipping orders are expected to be created in the last month.\n",
      "\n",
      "The result of this query is a single number, which is the number of temperature-qualified shipping orders in the last month.\n",
      "\n",
      "The query uses a subquery to determine the number of temperature-qualified shipping orders in the last month. This is because the query cannot reference the date directly in the WHERE clause. Instead, it must use a subquery to calculate the date based on the current date and the interval. This is because the date in the WHERE clause cannot be used in the comparison.\n",
      "\n",
      "The subquery uses the DATE_SUB function to subtract the interval from the current date. The INTERVAL keyword is followed by the number of months and the time unit. The unit can be YEAR, MONTH, DAY, HOUR, MINUTE, SECOND.\n",
      "\n",
      "The subquery is then used in the main query as the value of the date in the comparison. This is because the date in the WHERE clause cannot be used in the comparison.\n",
      "\n",
      "The query uses the COUNT function to count the number of rows in the result.\n",
      "\n",
      "The query uses the FROM clause to select from the table ads_bi_quality\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use CURDATE() function to get the current date, if the question involves \"today\".\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE ads_bi_quality_monitor_shipping_detail (\\n\\tshipping_order_code VARCHAR(100) COMMENT \\'派车单编码\\', \\n\\tlicense_plate VARCHAR(100) COMMENT \\'车牌号\\', \\n\\ttruck_type VARCHAR(50) COMMENT \\'车辆类型\\', \\n\\ttenant_id VARCHAR(100) COMMENT \\'租户编码\\', \\n\\ttenant_name VARCHAR(200) COMMENT \\'租户名称\\', \\n\\tfather_company_code VARCHAR(100) COMMENT \\'分子公司编码\\', \\n\\tfather_company_name VARCHAR(200) COMMENT \\'分子公司名称\\', \\n\\tfather_company_short_name VARCHAR(200) COMMENT \\'分子公司简称\\', \\n\\tstart_transport_time VARCHAR(50) COMMENT \\'运输出发时间\\', \\n\\tsigning_time VARCHAR(50) COMMENT \\'派车单签收时间\\', \\n\\tplan_start_time VARCHAR(50) COMMENT \\'派车单计划取货时间\\', \\n\\tplan_end_time VARCHAR(50) COMMENT \\'派车单计划送达时间\\', \\n\\tfrist_fence_time VARCHAR(50) COMMENT \\'第一次碰撞装货地电子围栏时间\\', \\n\\tleave_load_station_2km_time VARCHAR(50) COMMENT \\'离开最后一个装货地电子围栏2km的时间\\', \\n\\tfrist_arrive_unload_time VARCHAR(50) COMMENT \\'首次到达卸货点电子围栏时间\\', \\n\\ttransport_type VARCHAR(10) COMMENT \\'运输类型(干线/城配)\\', \\n\\tplan_mileage VARCHAR(50) COMMENT \\'计划里程\\', \\n\\tdriver_accept_time VARCHAR(50) COMMENT \\'司机接单时间\\', \\n\\tdriver_name VARCHAR(50) COMMENT \\'司机姓名\\', \\n\\tdriver_phone VARCHAR(50) COMMENT \\'司机电话\\', \\n\\tdriver_type VARCHAR(10) COMMENT \\'司机类型\\', \\n\\ttransport_tenant_id VARCHAR(100) COMMENT \\'运力承运商id\\', \\n\\ttransport_tenant_name VARCHAR(200) COMMENT \\'运力承运商名称\\', \\n\\twarm_area VARCHAR(50) COMMENT \\'温区信息\\', \\n\\twaybill_count INTEGER COMMENT \\'运单数量\\', \\n\\tgps_device_list VARCHAR(100) COMMENT \\'gps设备\\', \\n\\tgps_report_dot_num INTEGER COMMENT \\'gps上报点数\\', \\n\\ttemp_substandard_min DECIMAL(20, 8) COMMENT \\'温度不达标时长(分钟)\\', \\n\\ttemp_substandard_min_n12 DECIMAL(20, 8) COMMENT \\'温度不达标时长(分钟)_-12\\', \\n\\ttemp_substandard_min_n16 DECIMAL(20, 8) COMMENT \\'温度不达标时长(分钟)_-16\\', \\n\\tshipping_order_transport_min DECIMAL(20, 8) COMMENT \\'派车单运输总时长(分钟)\\', \\n\\tshipping_order_temp_standard_rate DECIMAL(20, 8) COMMENT \\'派车单温度达标率\\', \\n\\tshipping_order_temp_standard_rate_n12 DECIMAL(20, 8) COMMENT \\'派车单温度达标率_-12\\', \\n\\tshipping_order_temp_standard_rate_n16 DECIMAL(20, 8) COMMENT \\'派车单温度达标率_-16\\', \\n\\tdep_fence_match_num INTEGER COMMENT \\'出发地电子围栏匹配数量\\', \\n\\tdep_total_num INTEGER COMMENT \\'出发地总数量\\', \\n\\tdep_fence_match_rate DECIMAL(20, 8) COMMENT \\'出发地电子围栏匹配率\\', \\n\\tdes_fence_match_num INTEGER COMMENT \\'目的地电子围栏匹配数量\\', \\n\\tdes_total_num INTEGER COMMENT \\'目的地总数量\\', \\n\\tdes_fence_match_rate DECIMAL(20, 8) COMMENT \\'目的地电子围栏匹配率\\', \\n\\texception_shipping_order_type VARCHAR(10) COMMENT \\'异常派车单情况,0-非异常\\', \\n\\tsettlement_tenant_id VARCHAR(100) COMMENT \\'结算主体租户id\\', \\n\\tsettlement_tenant_name VARCHAR(100) COMMENT \\'结算主体租户名称\\', \\n\\ttruck_ownership VARCHAR(100) COMMENT \\'车辆所有权(自有/外请/临时)\\', \\n\\tload_finish_time VARCHAR(50) COMMENT \\'派车单点击装货完成时间\\', \\n\\tlast_leave_unload_time VARCHAR(50) COMMENT \\'最后离开卸货点时间\\', \\n\\ttemp_right_tag VARCHAR(20) COMMENT \\'温度是否合格(合格/不合格/不参与评估)\\', \\n\\twarm_area_type VARCHAR(20) COMMENT \\'温区类型。常温/冷链/自定义区间\\', \\n\\tsource_dt VARCHAR(20) COMMENT \\'派车单来源的增量表dt\\', \\n\\tcur_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT \\'当前派车单对应的客户\\', \\n\\tis_app_operation VARCHAR(10) COMMENT \\'是否APP操作卡控\\', \\n\\tleave_load_station_time_app VARCHAR(50) COMMENT \\'离开第一个装货地时间_app\\', \\n\\tfrist_arrive_unload_time_app VARCHAR(50) COMMENT \\'到达第一个卸货点时间_app\\', \\n\\tlast_arrive_unload_time_app VARCHAR(50) COMMENT \\'到达最后一个卸货点时间_app\\', \\n\\ttemp_calc_start_time VARCHAR(50) COMMENT \\'温度计算开始时间\\', \\n\\ttemp_calc_end_time VARCHAR(50) COMMENT \\'温度计算结束时间\\', \\n\\texception_shipping_order_type_desc VARCHAR(100) COMMENT \\'异常派车单情况描述\\', \\n\\troot_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT \\'根派车单对应的客户\\', \\n\\tis_use_custom_temp_range VARCHAR(10) COMMENT \\'是否使用自定义温度范围\\', \\n\\ttemp_eval_lowest INTEGER COMMENT \\'温度考核最低值\\', \\n\\ttemp_eval_highest INTEGER COMMENT \\'温度考核最高值\\', \\n\\tis_gps_cover VARCHAR(10) COMMENT \\'GPS是否覆盖\\', \\n\\tshipping_create_time VARCHAR(50) COMMENT \\'派车单创建时间\\', \\n\\tgps_device_list_plan VARCHAR(100) COMMENT \\'GPS设备_预估\\', \\n\\tis_gps_cover_plan VARCHAR(10) COMMENT \\'GPS是否覆盖_预估\\', \\n\\tfirst_station_is_on_time VARCHAR(10) COMMENT \\'首店是否准时\\', \\n\\tis_many_warm VARCHAR(10) COMMENT \\'是否多温区\\', \\n\\tmany_temp_standard_rate DECIMAL(20, 8) COMMENT \\'多温区温度达标率\\', \\n\\tlc_standard_ratio DECIMAL(20, 8) COMMENT \\'冷藏温度达标率\\', \\n\\tld_standard_ratio DECIMAL(20, 8) COMMENT \\'冷冻温度达标率\\', \\n\\tprobe_warm_list TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT \\'探头温区\\'\\n)DEFAULT CHARSET=utf8 COMMENT=\\'BI看板_品质监控_派车单明细\\' ENGINE=InnoDB\\n\\nQuestion: 最近一个月温度合格的派车单数量\\nSQLQuery: SELECT count(*) FROM ads_bi_quality_monitor_shipping_detail WHERE temp_right_tag = \\'合格\\' and DATE_SUB(CURDATE(), INTERVAL 1 MONTH) <= shipping_create_time;\\n\\nThe query above counts the number of shipping orders that were temperature-qualified in the last month. The temperature-qualified status is determined by the value of the column temp_right_tag. The date used in the comparison is the current date minus one month. This is because the shipping orders are expected to be created in the last month.\\n\\nThe result of this query is a single number, which is the number of temperature-qualified shipping orders in the last month.\\n\\nThe query uses a subquery to determine the number of temperature-qualified shipping orders in the last month. This is because the query cannot reference the date directly in the WHERE clause. Instead, it must use a subquery to calculate the date based on the current date and the interval. This is because the date in the WHERE clause cannot be used in the comparison.\\n\\nThe subquery uses the DATE_SUB function to subtract the interval from the current date. The INTERVAL keyword is followed by the number of months and the time unit. The unit can be YEAR, MONTH, DAY, HOUR, MINUTE, SECOND.\\n\\nThe subquery is then used in the main query as the value of the date in the comparison. This is because the date in the WHERE clause cannot be used in the comparison.\\n\\nThe query uses the COUNT function to count the number of rows in the result.\\n\\nThe query uses the FROM clause to select from the table ads_bi_quality'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "query=\"最近一个月温度合格的派车单数量\"\n",
    "output=agent_executor(\"\\n\\nHuman:'\"+query+\"'这个问题涉及的数据库表名是什么？\")\n",
    "#output=agent_executor.run(\"\\n\\nHuman:what's the database table related to the question of 'Number of qualified temperature delivery orders in the last month'?\")\n",
    "print(output)\n",
    "###process the agent output , retrave the table name####\n",
    "table_name=output[\"output\"].split(\" \")[-1].strip()\n",
    "table_name=table_name.split(\"数据库表名是\")[-1].strip()\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    \"mysql+pymysql://admin:admin12345678@database-us-west-2-demo.cluster-c1qvx9wzmmcz.us-west-2.rds.amazonaws.com/llm\",\n",
    "    sample_rows_in_table_info=0,\n",
    "    include_tables=[table_name])\n",
    "\n",
    "db_chain = CustomerizedSQLDatabaseChain.from_llm(sm_sql_llm, db, verbose=True, return_sql=True,return_intermediate_steps=False)\n",
    "response=db_chain.run(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a14b43-9f2e-467e-baec-1c69d5d5c3ef",
   "metadata": {},
   "source": [
    "* destroy agent and exectutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea174a-8fea-4afe-bb9d-63e35c4c650b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del agent_executor\n",
    "del llm_chain\n",
    "del agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054334d-a2b5-43bd-a8b7-fc99ebf2cba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
