{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1290f794-9477-4e45-ab20-81d04c040fc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## langcain agent demo for ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf80354-7edd-4403-9c8b-97a4712f4dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install langchain[all]\n",
    "#!pip install sagemaker --upgrade\n",
    "#!pip install  boto3\n",
    "#!pip install requests_aws4auth\n",
    "#!pip install opensearch-py\n",
    "#!pip install pydantic==1.10.0\n",
    "#!pip install PyAthena[SQLAlchemy]==1.0.0\n",
    "#!pip install PyAthena[JDBC]==1.0.0\n",
    "#!pip install openai\n",
    "!pip install sqlalchemy-redshift\n",
    "!pip install redshift_connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b216f11-a2b5-4f0b-b4de-060a1a64076a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## initial sagemaker env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19f05414-d44b-464e-a0c7-46c317378ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
      "sagemaker bucket: sagemaker-us-west-2-687912291502\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "from typing import Dict\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3aed78-e14b-4d30-93d3-2871d6603bd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## intial lanchain lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4aae9f94-a8df-49b5-b22b-f89e8d756b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferWindowMemory,ConversationBufferMemory\n",
    "from langchain import LLMChain\n",
    "from typing import Dict\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"]= \"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\"\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "aos_endpoint=\"vpc-llm-rag-aos-seg3mzhpp76ncpxezdqtcsoiga.us-west-2.es.amazonaws.com\"\n",
    "region='us-west-2'\n",
    "username=\"admin\"\n",
    "passwd=\"(OL>0p;/\"\n",
    "index_name=\"qa_index\"\n",
    "size=10\n",
    "\n",
    "## for chatglm\n",
    "class TextGenContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        #input_str = json.dumps({prompt: prompt, **model_kwargs})\n",
    "        input_str = json.dumps({\n",
    "                \"ask\": prompt,\n",
    "                \"parameters\": model_kwargs\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"answer\"]\n",
    "\n",
    "### for vicuna/llama\n",
    "class TextGenContentHandler2(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": model_kwargs\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"data\"][0][\"generated_text\"]   \n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "  \"early_stopping\": False,\n",
    "  #\"length_penalty\": 2.0,\n",
    "  #\"max_new_tokens\": 500,\n",
    "  \"temperature\": 0.6,\n",
    "  \"max_tokens\": 300,\n",
    "  #\"no_repeat_ngram_size\": 2,\n",
    "}\n",
    "sm_llm=SagemakerEndpoint(\n",
    "        #endpoint_name=\"chatglm-inference-0524-2023-06-01-07-11-27-379\",\n",
    "        endpoint_name=\"vicuna-7B-2023-06-04-13-07-39-746-endpoint\",\n",
    "        region_name=\"us-west-2\", \n",
    "        model_kwargs=parameters,\n",
    "        content_handler=TextGenContentHandler2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa302e0a-b8ed-4fa0-934e-ab4ff0740316",
   "metadata": {
    "tags": []
   },
   "source": [
    "## major chain pipeline ################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa19652-7785-42f6-a74f-bc31ff4ca28a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 直接使用 langchain SQLDatabaseChain \n",
    "定制SqlDataBase对接其他数据源(e.g StarRocks)   \n",
    "SqlDatabaseChain使用sagemaker endpoint llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "634c6070-af8c-40b7-b655-e6eb37eff456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT c_customer_id FROM web_sales ORDER BY ws_sold_price DESC LIMIT 1\n"
     ]
    }
   ],
   "source": [
    "sql_cmd=\"\"\"\n",
    "You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most 3 results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "Question: 我需要知道销售报表中，下单金额最大的客户id\n",
    "SQLQuery: SELECT c_customer_id FROM web_sales ORDER BY ws_sold_price DESC LIMIT 1\n",
    "SQLResult\n",
    "SQL Query to run\"\"\"\n",
    "pattern = r\"SQLQuery: (.*?)\\nSQLResult\"\n",
    "matches = re.findall(pattern, sql_cmd)\n",
    "match = matches[1]\n",
    "sql_cmd = match\n",
    "sql_cmd=sql_cmd.replace(\"SQLQuery:\",\"\")\n",
    "sql_cmd=sql_cmd.replace(\"SQLResult\",\"\")\n",
    "sql_cmd=sql_cmd.replace(\"\\\\\",\"\")\n",
    "print(sql_cmd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "781f2be7-0a3e-4eac-a55b-00b182762326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"SQLAlchemy wrapper around a database.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "from typing import Any, Iterable, List, Optional\n",
    "import sqlalchemy\n",
    "import re\n",
    "from langchain.chains.base import Chain\n",
    "from langchain import OpenAI, SQLDatabase,SQLDatabaseChain\n",
    "from langchain.base_language import BaseLanguageModel\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from sqlalchemy import MetaData, Table, create_engine, inspect, select, text\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy.exc import ProgrammingError, SQLAlchemyError\n",
    "from sqlalchemy.schema import CreateTable\n",
    "\n",
    "from langchain import utils\n",
    "\n",
    "\n",
    "class CustomerizedSQLDatabase(SQLDatabase):\n",
    "    \n",
    "    def get_table_info(self, table_names: Optional[List[str]] = None) -> str:\n",
    "        \"\"\"Get information about specified tables.\n",
    "\n",
    "        Follows best practices as specified in: Rajkumar et al, 2022\n",
    "        (https://arxiv.org/abs/2204.00498)\n",
    "\n",
    "        If `sample_rows_in_table_info`, the specified number of sample rows will be\n",
    "        appended to each table description. This can increase performance as\n",
    "        demonstrated in the paper.\n",
    "        \"\"\"\n",
    "        all_table_names = self.get_usable_table_names()\n",
    "        if table_names is not None:\n",
    "            missing_tables = set(table_names).difference(all_table_names)\n",
    "            if missing_tables:\n",
    "                raise ValueError(f\"table_names {missing_tables} not found in database\")\n",
    "            all_table_names = table_names\n",
    "\n",
    "        meta_tables = [\n",
    "            tbl\n",
    "            for tbl in self._metadata.sorted_tables\n",
    "            if tbl.name in set(all_table_names)\n",
    "            and not (self.dialect == \"sqlite\" and tbl.name.startswith(\"sqlite_\"))\n",
    "        ]\n",
    "\n",
    "        tables = []\n",
    "        for table in meta_tables:\n",
    "            if self._custom_table_info and table.name in self._custom_table_info:\n",
    "                tables.append(self._custom_table_info[table.name])\n",
    "                continue\n",
    "\n",
    "            # add create table command\n",
    "            create_table = str(CreateTable(table).compile(self._engine))\n",
    "            table_info = f\"{create_table.rstrip()}\"\n",
    "            has_extra_info = (\n",
    "                self._indexes_in_table_info or self._sample_rows_in_table_info\n",
    "            )\n",
    "            if has_extra_info:\n",
    "                table_info += \"\\n\\n/*\"\n",
    "            if self._indexes_in_table_info:\n",
    "                table_info += f\"\\n{self._get_table_indexes(table)}\\n\"\n",
    "            if self._sample_rows_in_table_info:\n",
    "                table_info += f\"\\n{self._get_sample_rows(table)}\\n\"\n",
    "            if has_extra_info:\n",
    "                table_info += \"*/\"\n",
    "            tables.append(table_info)\n",
    "        final_str = \"\\n\\n\".join(tables)\n",
    "        return final_str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomerizedSQLDatabaseChain(SQLDatabaseChain):\n",
    "    def _call(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
    "        input_text = f\"{inputs[self.input_key]}\\nSQLQuery:\"\n",
    "        _run_manager.on_text(input_text, verbose=self.verbose)\n",
    "        # If not present, then defaults to None which is all tables.\n",
    "        table_names_to_use = inputs.get(\"table_names_to_use\")\n",
    "        if table_names_to_use is None:\n",
    "            table_names_to_use = self.database._include_tables\n",
    "        table_info = self.database.get_table_info(table_names=list(table_names_to_use))\n",
    "        llm_inputs = {\n",
    "            \"input\": input_text,\n",
    "            \"top_k\": str(self.top_k),\n",
    "            \"dialect\": self.database.dialect,\n",
    "            \"table_info\": table_info,\n",
    "            #\"stop\": [\"\\nSQLResult:\"],\n",
    "        }\n",
    "        intermediate_steps: List = []\n",
    "        try:\n",
    "            intermediate_steps.append(llm_inputs)  # input: sql generation\n",
    "            sql_cmd = self.llm_chain.predict(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **llm_inputs,\n",
    "            ).strip()\n",
    "            if not self.use_query_checker:\n",
    "                _run_manager.on_text(sql_cmd, color=\"green\", verbose=self.verbose)\n",
    "                intermediate_steps.append(\n",
    "                    sql_cmd\n",
    "                )  # output: sql generation (no checker)\n",
    "                intermediate_steps.append({\"sql_cmd\": sql_cmd})  # input: sql exec\n",
    "                ###定制 解析chatglm的输出sql，尝试抽取原始'''内的sql#######\n",
    "                pattern = r\"```([^.]*)```\"\n",
    "                matches = re.findall(pattern, sql_cmd)\n",
    "                for match in matches:\n",
    "                   sql_cmd = match\n",
    "                   sql_cmd=sql_cmd.replace(\"```\",\"\")\n",
    "                   sql_cmd=sql_cmd.replace(\"sql\",\"\")\n",
    "                #########################################################\n",
    "                \n",
    "                ###定制 解析vicuna的输出sql，尝试抽取原始SQLQuery:和Answer: 内的sql#######\n",
    "                #pattern = r\"SQLQuery: (.*?)\\nAnswer\"\n",
    "                #matches = re.findall(pattern, sql_cmd)\n",
    "                #match = matches[0]\n",
    "                #sql_cmd = match\n",
    "                #sql_cmd=sql_cmd.replace(\"SQLQuery:\",\"\")\n",
    "                #sql_cmd=sql_cmd.replace(\"Answer\",\"\")\n",
    "                #sql_cmd=sql_cmd.replace(\"\\\\\",\"\")\n",
    "                #print(sql_cmd) \n",
    "                #########################################################\n",
    "                \n",
    "                \n",
    "                 ###定制 解析bloomz的输出sql，尝试抽取原始SQLQuery:和SQLResult: 内的sql#######\n",
    "                pattern = r\"SQLQuery: (.*?)\\nSQLResult\"\n",
    "                print(\"sql_cmd original==\"+sql_cmd)\n",
    "                matches = re.findall(pattern, sql_cmd)\n",
    "                match = matches[1]\n",
    "                sql_cmd = match\n",
    "                sql_cmd=sql_cmd.replace(\"SQLQuery:\",\"\")\n",
    "                sql_cmd=sql_cmd.replace(\"SQLResult\",\"\")\n",
    "                sql_cmd=sql_cmd.replace(\"\\\\\",\"\")\n",
    "                print(sql_cmd) \n",
    "                #########################################################\n",
    "                \n",
    "                result = self.database.run(sql_cmd)\n",
    "                intermediate_steps.append(str(result))  # output: sql exec\n",
    "            else:\n",
    "                query_checker_prompt = self.query_checker_prompt or PromptTemplate(\n",
    "                    template=QUERY_CHECKER, input_variables=[\"query\", \"dialect\"]\n",
    "                )\n",
    "                query_checker_chain = LLMChain(\n",
    "                    llm=self.llm_chain.llm, prompt=query_checker_prompt\n",
    "                )\n",
    "                print(\"here2===\"+sql_cmd)\n",
    "                query_checker_inputs = {\n",
    "                    \"query\": sql_cmd,\n",
    "                    \"dialect\": self.database.dialect,\n",
    "                }\n",
    "                checked_sql_command: str = query_checker_chain.predict(\n",
    "                    callbacks=_run_manager.get_child(), **query_checker_inputs\n",
    "                ).strip()\n",
    "                intermediate_steps.append(\n",
    "                    checked_sql_command\n",
    "                )  # output: sql generation (checker)\n",
    "                _run_manager.on_text(\n",
    "                    checked_sql_command, color=\"green\", verbose=self.verbose\n",
    "                )\n",
    "                intermediate_steps.append(\n",
    "                    {\"sql_cmd\": checked_sql_command}\n",
    "                )  # input: sql exec\n",
    "                \n",
    "                result = self.database.run(checked_sql_command)\n",
    "                intermediate_steps.append(str(result))  # output: sql exec\n",
    "                sql_cmd = checked_sql_command\n",
    "\n",
    "            _run_manager.on_text(\"\\nSQLResult: \", verbose=self.verbose)\n",
    "            _run_manager.on_text(result, color=\"yellow\", verbose=self.verbose)\n",
    "            # If return direct, we just set the final result equal to\n",
    "            # the result of the sql query result, otherwise try to get a human readable\n",
    "            # final answer\n",
    "\n",
    "            if self.return_direct:\n",
    "                final_result = result\n",
    "            else:\n",
    "                print(\"here8888===\")\n",
    "                print(llm_inputs)\n",
    "                _run_manager.on_text(\"\\nAnswer:\", verbose=self.verbose)\n",
    "                input_text += f\"{sql_cmd}\\nSQLResult: {result}\\nAnswer:\"\n",
    "                llm_inputs[\"input\"] = input_text\n",
    "                intermediate_steps.append(llm_inputs)  # input: final answer\n",
    "                final_result = self.llm_chain.predict(\n",
    "                    callbacks=_run_manager.get_child(),\n",
    "                    **llm_inputs,\n",
    "                ).strip()\n",
    "                intermediate_steps.append(final_result)  # output: final answer\n",
    "                _run_manager.on_text(final_result, color=\"green\", verbose=self.verbose)\n",
    "            chain_result: Dict[str, Any] = {self.output_key: final_result}\n",
    "            if self.return_intermediate_steps:\n",
    "                chain_result[INTERMEDIATE_STEPS_KEY] = intermediate_steps\n",
    "            return chain_result\n",
    "        except Exception as exc:\n",
    "            # Append intermediate steps to exception, to aid in logging and later\n",
    "            # improvement of few shot prompt seeds\n",
    "            exc.intermediate_steps = intermediate_steps  # type: ignore\n",
    "            raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bc28c0b2-3169-4d67-a083-041d31b507f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to load default session, using empty session: HTTPConnectionPool(host='localhost', port=1984): Max retries exceeded with url: /sessions?name=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0caff0a7f0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "我需要知道销售报表中，下单金额的平均数最大的客户id\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT c_customer_id, AVG(ws_net_paid) AS avg_net_paid \n",
      "FROM customer \n",
      "INNER JOIN web_sales ON c_customer_sk = ws_bill_customer_sk \n",
      "GROUP BY c_customer_id \n",
      "ORDER BY avg_net_paid DESC \n",
      "LIMIT 3;\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('AAAAAAAAOCIDIAAA', Decimal('7751.353750')), ('AAAAAAAAGFKBHAAA', Decimal('7730.946250')), ('AAAAAAAAOJKHGAAA', Decimal('7603.959000'))]\u001b[0m\n",
      "Answer:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to persist run: HTTPConnectionPool(host='localhost', port=1984): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0ce8e866d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m最大的客户id是AAAAAAAAOCIDIAAA\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'最大的客户id是AAAAAAAAOCIDIAAA'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## langchain agent demo test##########\n",
    "from langchain import OpenAI, SQLDatabase,SQLDatabaseChain\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.environ[\"PGPASSWORD\"] = \"*******\"\n",
    "os.environ[\"LANGCHAIN_HANDLER\"] = \"langchain\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-3lTxHcynfeJ4*******lbkFJz4k968DnZNADqgT583TF\"\n",
    "conn_str = \"awsathena+rest://{aws_access_key_id}:{aws_secret_access_key}@athena.{region_name}.amazonaws.com:443/\"\\\n",
    "           \"{schema_name}?s3_staging_dir={s3_staging_dir}\"\n",
    "conn_str = conn_str.format(\n",
    "    aws_access_key_id=\"**********\",\n",
    "    aws_secret_access_key=\"***********\",\n",
    "    region_name=\"us-west-2\",\n",
    "    schema_name=\"specturmdb\",\n",
    "    s3_staging_dir=\"s3://tangqy-athenaoutput-us-west-2\")\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    #conn_str,\n",
    "    #\"redshift+redshift_connector://admin@redshift-cluster-1.cp1kgq7oikv3.ap-southeast-1.redshift.amazonaws.com:5439/dev\",\n",
    "    \"mysql+pymysql://admin:******@database-us-west-2-demo.cluster-c1qvx9wzmmcz.us-west-2.rds.amazonaws.com/llm\",\n",
    "    #\"jdbc:awsathena://athena.us-west-2.amazonaws.com:443/tpcds_bin_partitioned_orc_300?s3_staging_dir=s3://tangqy-athenaoutput/&aws_credentials_provider_class=com.amazonaws.auth.DefaultAWSCredentialsProviderChain\",\n",
    "    include_tables=['web_sales','customer'], # we include only one table to save tokens in the prompt :)\n",
    "    #include_tables=[\"tpcds_text_1000.web_sales\",\"tpcds_text_1000.customer\"],\n",
    "    sample_rows_in_table_info=0)\n",
    "llm = OpenAI(temperature=0, verbose=True)\n",
    "#db_chain = CustomerizedSQLDatabaseChain(llm=llm, database=db, verbose=True, top_k=3)\n",
    "db_chain = SQLDatabaseChain(llm=sm_llm, database=db, verbose=True, top_k=3)\n",
    "\n",
    "db_chain.run(\"我需要知道销售报表中，下单金额的平均数最大的客户id\")\n",
    "#db_chain.run(\"I need to know the max sales customer's id in sales report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e85c1-44e8-4736-93d7-9571a2642bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_chain = CustomerizedSQLDatabaseChain(llm=sm_llm, database=db, verbose=True, top_k=3)\n",
    "db_chain.run(\"我需要知道销售报表中，下单金额最大的客户id\")\n",
    "#db_chain.run(\"I need to know the max sales customer's id in web_sales report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac4e51-32b7-460f-adee-b20151163e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "region = boto3.Session().region_name\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, 'es', session_token=credentials.token)\n",
    "\n",
    "class CustomEmbeddingSearchTool(BaseTool):\n",
    "    name = \"custom_knn_search\"\n",
    "    aos_client = OpenSearch(\n",
    "                hosts=[{'host': aos_endpoint, 'port': 443}],\n",
    "                http_auth = awsauth,\n",
    "                use_ssl=True,\n",
    "                verify_certs=True,\n",
    "                connection_class=RequestsHttpConnection)\n",
    "    aos_index=\"metadata_labels\"\n",
    "        \n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Opensearch 向量检索.\"\"\"\n",
    "        start = time.time()\n",
    "        query_embedding = get_vector_by_sm_endpoint(query, sm_client, sm_embeddings)\n",
    "        elpase_time = time.time() - start\n",
    "        print(f'runing time of opensearch_knn : {elpase_time}s seconds')\n",
    "        return get_topk_item(aos_knn_search(client, q_embedding, aos_index, size=10),2)\n",
    "         \n",
    "        \n",
    "   \n",
    "\n",
    "class CustomReverseIndexSearchTool(BaseTool):\n",
    "    name = \"custom_reverse_search\"\n",
    "    aos_client = OpenSearch(\n",
    "                hosts=[{'host': aos_endpoint, 'port': 443}],\n",
    "                http_auth = awsauth,\n",
    "                use_ssl=True,\n",
    "                verify_certs=True,\n",
    "                connection_class=RequestsHttpConnection)\n",
    "    aos_index=\"metadata_labels\"\n",
    "    \n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Opensearch 标签检索.\"\"\"\n",
    "        start = time.time()\n",
    "        opensearch_query_response = aos_reverse_search(aos_client, aos_index, \"doc\", query_input)\n",
    "        # logger.info(opensearch_query_response)\n",
    "        elpase_time = time.time() - start\n",
    "        logger.info(f'runing time of opensearch_query : {elpase_time}s seconds')\n",
    "        return get_topk_item(opensearch_query_response,2)\n",
    "        \n",
    "\n",
    "\n",
    "custom_tool_list=[]\n",
    "custom_tool_list.append(\n",
    "    Tool(\n",
    "        func=CustomReverseIndexSearchTool.run,\n",
    "        name=\"reverse index search\",\n",
    "        description=\"用于向量检索找到具体的数据库和表名\"\n",
    "    )  \n",
    ")\n",
    "\n",
    "custom_tool_list.append(\n",
    "    Tool(\n",
    "        func=CustomEmbeddingSearchTool.run,\n",
    "        name=\"embedding knn search\",\n",
    "        description=\"用于标签检索找到具体的数据库和表名\"\n",
    "    )    \n",
    ")\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    \"mysql+pymysql://admin:******@database-us-west-2-demo.cluster-c1qvx9wzmmcz.us-west-2.rds.amazonaws.com/llm\",\n",
    "    sample_rows_in_table_info=0)\n",
    "\n",
    "sm_llm=SagemakerEndpoint(\n",
    "        #endpoint_name=\"chatglm-inference-0524-2023-06-01-07-11-27-379\",\n",
    "        endpoint_name=\"vicuna-7B-2023-06-04-13-07-39-746-endpoint\",\n",
    "        region_name=\"us-west-2\", \n",
    "        model_kwargs=parameters,\n",
    "        content_handler=text_gen_content_handler3\n",
    ")\n",
    "\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=sm_llm)\n",
    "\n",
    "custom_suffix = \"\"\"\n",
    "我应该先利用标签检索，找到具体的数据库和表名，\n",
    "如果找不到，则利用向量检索查找，\n",
    "然后使用数据库工具查看我刚才找到的应该查询的库和表的详细schema元数据。\n",
    "\"\"\"\n",
    "agent = create_sql_agent(llm=llm,\n",
    "                         toolkit=toolkit,\n",
    "                         verbose=True,\n",
    "                         agent_type=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         extra_tools=custom_tool_list,\n",
    "                         suffix=custom_suffix\n",
    "                        )\n",
    "\n",
    "agent.run(\"我需要知道销售报表中，下单金额最大的客户id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf8dfb-6487-4679-bd40-ec2d1d6693d7",
   "metadata": {},
   "source": [
    "* zero shot Agent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147d7fc-0b40-45f4-869e-213546026632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain import OpenAI, LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "chatglm_db_prompt_template = \"\"\"你是MySQL的专家。给定一个输入问题，创建一个语法正确的MySQL查询语句。\n",
    "除非用户在问题中指定了要获得的特定数量的示例，否则使用LIMIT子句查询最多{top_k}个结果。您可以对结果进行排序，以返回数据库中信息量最大的数据。您必须仅查询回答问题所需的列。将每个列名用反引号（`）括起来，表示为分隔的标识符。\n",
    "请注意，仅可以使用在{table_info}这些表中看到的列名，不要查询不存在的列。此外，还要注意哪个列在哪个表中。如果问题涉及”今天”，请注意使用CURDATE()函数获取当前日期.\n",
    "使用以下格式：\n",
    "Question:此处为问题\n",
    "SQLQuery:要运行的SQL查询\n",
    "SQLResult:SQLQuery的结果\n",
    "Answer:此处为最终答案\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT_SUFFIX = \"\"\"Question:{input}\"\"\"\n",
    "\n",
    "chatglm_db_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"top_k\"],\n",
    "    template=chatglm_db_prompt_template+PROMPT_SUFFIX,\n",
    ")\n",
    "\n",
    "\n",
    "#from langchain.chains.question_answering import load_qa_chain\n",
    "#chain = LLMChain(llm=sm_llm,prompt=chatglm_db_prompt)\n",
    "#chain.run({\"input\":\"我需要知道销售报表中，下单金额最大的客户id\",\"table_info\":\"'web_sales','customer'\",\"top_k\":\"3\"})\n",
    "\n",
    "\n",
    "#db_chain = CustomerizedSQLDatabaseChain.from_llm(llm=sm_llm, prompt=chatglm_db_prompt,db=db, verbose=True, top_k=3)\n",
    "db_chain = CustomerizedSQLDatabaseChain.from_llm(llm=sm_llm, db=db, verbose=True, top_k=3)\n",
    "db_chain.run(\"我需要知道销售报表中，下单金额最大的客户id\")\n",
    "#db_chain.run(\"帮我查下销售报表中，最大的销售金额\")\n",
    "\n",
    "#tools = []\n",
    "#prefix = \"\"\"尽你所能回答以下问题。您可以访问以下工具\"\"\"\n",
    "#suffix = \"\"\"开始! \n",
    "#\n",
    "#问题: {input}\n",
    "#{agent_scratchpad}\"\"\"\n",
    "#\n",
    "#prompt = ZeroShotAgent.create_prompt(\n",
    "#    tools, \n",
    "#    prefix=prefix, \n",
    "#    suffix=suffix, \n",
    "#    input_variables=[\"input\", \"agent_scratchpad\"]\n",
    "#)\n",
    "#\n",
    "##class AnalyzeInput(BaseModel):\n",
    "##    query: str = Field()\n",
    "#\n",
    "#print(prompt.template)\n",
    "#llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "#agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n",
    "#agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "#agent_executor.run(\"我需要知道llm数据库的web_sales销售报表中，ws_quantity和ws_ext_sales_price乘积最大的客户的c_customer_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
